<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Semiparametric estimation and inference | Notes on Statistical Thinking from Scratch</title>
  <meta name="description" content="Cliff notes for Statistical Thinking from Scratch, by Doc Edge." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Semiparametric estimation and inference | Notes on Statistical Thinking from Scratch" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Cliff notes for Statistical Thinking from Scratch, by Doc Edge." />
  <meta name="github-repo" content="elahi/stats_from_scratch_edge" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Semiparametric estimation and inference | Notes on Statistical Thinking from Scratch" />
  
  <meta name="twitter:description" content="Cliff notes for Statistical Thinking from Scratch, by Doc Edge." />
  

<meta name="author" content="Robin Elahi" />


<meta name="date" content="2020-08-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="intervals.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-121894527-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-121894527-4');
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notes on Statistical Thinking from Scratch</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="r-eda.html"><a href="r-eda.html"><i class="fa fa-check"></i><b>2</b> R and exploratory data analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="r-eda.html"><a href="r-eda.html#inspecting-the-dataframe"><i class="fa fa-check"></i><b>2.1</b> Inspecting the dataframe</a></li>
<li class="chapter" data-level="2.2" data-path="r-eda.html"><a href="r-eda.html#histograms"><i class="fa fa-check"></i><b>2.2</b> Histograms</a></li>
<li class="chapter" data-level="2.3" data-path="r-eda.html"><a href="r-eda.html#summarising-data"><i class="fa fa-check"></i><b>2.3</b> Summarising data</a></li>
<li class="chapter" data-level="2.4" data-path="r-eda.html"><a href="r-eda.html#loops"><i class="fa fa-check"></i><b>2.4</b> Loops</a></li>
<li class="chapter" data-level="2.5" data-path="r-eda.html"><a href="r-eda.html#functions"><i class="fa fa-check"></i><b>2.5</b> Functions</a></li>
<li class="chapter" data-level="2.6" data-path="r-eda.html"><a href="r-eda.html#boxplots"><i class="fa fa-check"></i><b>2.6</b> Boxplots</a></li>
<li class="chapter" data-level="2.7" data-path="r-eda.html"><a href="r-eda.html#scatterplots"><i class="fa fa-check"></i><b>2.7</b> Scatterplots</a></li>
<li class="chapter" data-level="2.8" data-path="r-eda.html"><a href="r-eda.html#exercise-set-2-2"><i class="fa fa-check"></i><b>2.8</b> Exercise set 2-2</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="best-fit-line.html"><a href="best-fit-line.html"><i class="fa fa-check"></i><b>3</b> Line of best fit</a><ul>
<li class="chapter" data-level="3.1" data-path="best-fit-line.html"><a href="best-fit-line.html#exercise-set-3-1"><i class="fa fa-check"></i><b>3.1</b> Exercise set 3-1</a></li>
<li class="chapter" data-level="3.2" data-path="best-fit-line.html"><a href="best-fit-line.html#exercise-set-3-2"><i class="fa fa-check"></i><b>3.2</b> Exercise set 3-2</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>4</b> Probability and random variables</a><ul>
<li class="chapter" data-level="4.0.1" data-path="probability.html"><a href="probability.html#probability-vs-estimation"><i class="fa fa-check"></i><b>4.0.1</b> Probability vs estimation</a></li>
<li class="chapter" data-level="4.0.2" data-path="probability.html"><a href="probability.html#what-is-a-probability"><i class="fa fa-check"></i><b>4.0.2</b> What is a probability?</a></li>
<li class="chapter" data-level="4.0.3" data-path="probability.html"><a href="probability.html#set-notation"><i class="fa fa-check"></i><b>4.0.3</b> Set notation</a></li>
<li class="chapter" data-level="4.1" data-path="probability.html"><a href="probability.html#kolmogorovs-three-axioms-of-probability"><i class="fa fa-check"></i><b>4.1</b> Kolmogorov’s three axioms of probability</a><ul>
<li class="chapter" data-level="4.1.1" data-path="probability.html"><a href="probability.html#exercise-set-4-1"><i class="fa fa-check"></i><b>4.1.1</b> Exercise set 4-1</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="probability.html"><a href="probability.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>4.2</b> Conditional probability and independence</a><ul>
<li class="chapter" data-level="4.2.1" data-path="probability.html"><a href="probability.html#exercise-set-4-2"><i class="fa fa-check"></i><b>4.2.1</b> Exercise set 4-2</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="probability.html"><a href="probability.html#bayes-theorem"><i class="fa fa-check"></i><b>4.3</b> Bayes’ Theorem</a></li>
<li class="chapter" data-level="4.4" data-path="probability.html"><a href="probability.html#discrete-random-variables-and-distributions"><i class="fa fa-check"></i><b>4.4</b> Discrete random variables and distributions</a><ul>
<li class="chapter" data-level="4.4.1" data-path="probability.html"><a href="probability.html#exercise-set-4-3"><i class="fa fa-check"></i><b>4.4.1</b> Exercise set 4-3</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="probability.html"><a href="probability.html#continuous-random-variables-and-distributions"><i class="fa fa-check"></i><b>4.5</b> Continuous random variables and distributions</a><ul>
<li class="chapter" data-level="4.5.1" data-path="probability.html"><a href="probability.html#exercise-set-4-4"><i class="fa fa-check"></i><b>4.5.1</b> Exercise set 4-4</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="probability.html"><a href="probability.html#probability-density-functions"><i class="fa fa-check"></i><b>4.6</b> Probability density functions</a><ul>
<li class="chapter" data-level="4.6.1" data-path="probability.html"><a href="probability.html#additional-viz"><i class="fa fa-check"></i><b>4.6.1</b> Additional viz</a></li>
<li class="chapter" data-level="4.6.2" data-path="probability.html"><a href="probability.html#exercise-set-4-5"><i class="fa fa-check"></i><b>4.6.2</b> Exercise set 4-5</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="probability.html"><a href="probability.html#families-of-distributions"><i class="fa fa-check"></i><b>4.7</b> Families of distributions</a><ul>
<li class="chapter" data-level="4.7.1" data-path="probability.html"><a href="probability.html#exercise-set-4-6"><i class="fa fa-check"></i><b>4.7.1</b> Exercise set 4-6</a></li>
<li class="chapter" data-level="4.7.2" data-path="probability.html"><a href="probability.html#additional-exercise"><i class="fa fa-check"></i><b>4.7.2</b> Additional exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="randomvars.html"><a href="randomvars.html"><i class="fa fa-check"></i><b>5</b> Properties of random variables</a><ul>
<li class="chapter" data-level="5.1" data-path="randomvars.html"><a href="randomvars.html#expected-values-and-the-law-of-large-numbers"><i class="fa fa-check"></i><b>5.1</b> Expected values and the law of large numbers</a><ul>
<li class="chapter" data-level="5.1.1" data-path="randomvars.html"><a href="randomvars.html#weak-law-of-large-numbers"><i class="fa fa-check"></i><b>5.1.1</b> Weak law of large numbers</a></li>
<li class="chapter" data-level="5.1.2" data-path="randomvars.html"><a href="randomvars.html#handy-facts-about-expectations"><i class="fa fa-check"></i><b>5.1.2</b> Handy facts about expectations</a></li>
<li class="chapter" data-level="5.1.3" data-path="randomvars.html"><a href="randomvars.html#exercise-set-5-1"><i class="fa fa-check"></i><b>5.1.3</b> Exercise set 5-1</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="randomvars.html"><a href="randomvars.html#variance-and-standard-deviation"><i class="fa fa-check"></i><b>5.2</b> Variance and standard deviation</a><ul>
<li class="chapter" data-level="5.2.1" data-path="randomvars.html"><a href="randomvars.html#beautiful-properties-of-the-variance"><i class="fa fa-check"></i><b>5.2.1</b> Beautiful properties of the variance</a></li>
<li class="chapter" data-level="5.2.2" data-path="randomvars.html"><a href="randomvars.html#exercise-set-5-2"><i class="fa fa-check"></i><b>5.2.2</b> Exercise set 5-2</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="randomvars.html"><a href="randomvars.html#joint-distributions-covariance-and-correlation"><i class="fa fa-check"></i><b>5.3</b> Joint distributions, covariance, and correlation</a><ul>
<li class="chapter" data-level="5.3.1" data-path="randomvars.html"><a href="randomvars.html#joint-probability-distributions"><i class="fa fa-check"></i><b>5.3.1</b> Joint probability distributions</a></li>
<li class="chapter" data-level="5.3.2" data-path="randomvars.html"><a href="randomvars.html#marginal-distributions"><i class="fa fa-check"></i><b>5.3.2</b> Marginal distributions</a></li>
<li class="chapter" data-level="5.3.3" data-path="randomvars.html"><a href="randomvars.html#covariance"><i class="fa fa-check"></i><b>5.3.3</b> Covariance</a></li>
<li class="chapter" data-level="5.3.4" data-path="randomvars.html"><a href="randomvars.html#correlation"><i class="fa fa-check"></i><b>5.3.4</b> Correlation</a></li>
<li class="chapter" data-level="5.3.5" data-path="randomvars.html"><a href="randomvars.html#additional-exercise-1"><i class="fa fa-check"></i><b>5.3.5</b> Additional exercise</a></li>
<li class="chapter" data-level="5.3.6" data-path="randomvars.html"><a href="randomvars.html#exercise-set-5-3"><i class="fa fa-check"></i><b>5.3.6</b> Exercise set 5-3</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="randomvars.html"><a href="randomvars.html#conditional-distribution-expectation-variance"><i class="fa fa-check"></i><b>5.4</b> Conditional distribution, expectation, variance</a></li>
<li class="chapter" data-level="5.5" data-path="randomvars.html"><a href="randomvars.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>5.5</b> The central limit theorem</a><ul>
<li class="chapter" data-level="5.5.1" data-path="randomvars.html"><a href="randomvars.html#exercise-set-5-4"><i class="fa fa-check"></i><b>5.5.1</b> Exercise set 5-4</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="randomvars.html"><a href="randomvars.html#a-probabilistic-model-for-simple-linear-regression"><i class="fa fa-check"></i><b>5.6</b> A probabilistic model for simple linear regression</a><ul>
<li class="chapter" data-level="5.6.1" data-path="randomvars.html"><a href="randomvars.html#assumptions-of-the-linear-model"><i class="fa fa-check"></i><b>5.6.1</b> Assumptions of the linear model</a></li>
<li class="chapter" data-level="5.6.2" data-path="randomvars.html"><a href="randomvars.html#important-claims-that-follow-from-these-assumptions"><i class="fa fa-check"></i><b>5.6.2</b> Important claims that follow from these assumptions</a></li>
<li class="chapter" data-level="5.6.3" data-path="randomvars.html"><a href="randomvars.html#checking-these-assumptions"><i class="fa fa-check"></i><b>5.6.3</b> Checking these assumptions</a></li>
<li class="chapter" data-level="5.6.4" data-path="randomvars.html"><a href="randomvars.html#exercise-set-5-5"><i class="fa fa-check"></i><b>5.6.4</b> Exercise set 5-5</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="estimators.html"><a href="estimators.html"><i class="fa fa-check"></i><b>6</b> Properties of point estimators</a><ul>
<li class="chapter" data-level="6.1" data-path="estimators.html"><a href="estimators.html#bias"><i class="fa fa-check"></i><b>6.1</b> Bias</a><ul>
<li class="chapter" data-level="6.1.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-1"><i class="fa fa-check"></i><b>6.1.1</b> Exercise set 6-1</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="estimators.html"><a href="estimators.html#variance"><i class="fa fa-check"></i><b>6.2</b> Variance</a><ul>
<li class="chapter" data-level="6.2.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-2"><i class="fa fa-check"></i><b>6.2.1</b> Exercise set 6-2</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="estimators.html"><a href="estimators.html#mean-squared-error"><i class="fa fa-check"></i><b>6.3</b> Mean squared error</a><ul>
<li class="chapter" data-level="6.3.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-3"><i class="fa fa-check"></i><b>6.3.1</b> Exercise set 6-3</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="estimators.html"><a href="estimators.html#consistency"><i class="fa fa-check"></i><b>6.4</b> Consistency</a><ul>
<li class="chapter" data-level="6.4.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-4"><i class="fa fa-check"></i><b>6.4.1</b> Exercise set 6-4</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="estimators.html"><a href="estimators.html#efficiency"><i class="fa fa-check"></i><b>6.5</b> Efficiency</a><ul>
<li class="chapter" data-level="6.5.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-5"><i class="fa fa-check"></i><b>6.5.1</b> Exercise set 6-5</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="estimators.html"><a href="estimators.html#statistical-decision-theory-and-risk"><i class="fa fa-check"></i><b>6.6</b> Statistical decision theory and risk</a></li>
<li class="chapter" data-level="6.7" data-path="estimators.html"><a href="estimators.html#robustness"><i class="fa fa-check"></i><b>6.7</b> Robustness</a><ul>
<li class="chapter" data-level="6.7.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-8"><i class="fa fa-check"></i><b>6.7.1</b> Exercise set 6-8</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="estimators.html"><a href="estimators.html#estimators-for-simple-linear-regression"><i class="fa fa-check"></i><b>6.8</b> Estimators for simple linear regression</a><ul>
<li class="chapter" data-level="6.8.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-9"><i class="fa fa-check"></i><b>6.8.1</b> Exercise set 6-9</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="intervals.html"><a href="intervals.html"><i class="fa fa-check"></i><b>7</b> Interval estimation and inference</a><ul>
<li class="chapter" data-level="7.1" data-path="intervals.html"><a href="intervals.html#standard-error"><i class="fa fa-check"></i><b>7.1</b> Standard error</a><ul>
<li class="chapter" data-level="7.1.1" data-path="intervals.html"><a href="intervals.html#exercise-set-7-1"><i class="fa fa-check"></i><b>7.1.1</b> Exercise set 7-1</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="intervals.html"><a href="intervals.html#confidence-intervals"><i class="fa fa-check"></i><b>7.2</b> Confidence intervals</a><ul>
<li class="chapter" data-level="7.2.1" data-path="intervals.html"><a href="intervals.html#exercise-set-7-2"><i class="fa fa-check"></i><b>7.2.1</b> Exercise set 7-2</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="intervals.html"><a href="intervals.html#frequentist-inference-i-null-hypotheses-test-statistics-and-p-values"><i class="fa fa-check"></i><b>7.3</b> Frequentist inference I: null hypotheses, test statistics, and <em>p</em> values</a><ul>
<li class="chapter" data-level="7.3.1" data-path="intervals.html"><a href="intervals.html#exercise-set-7-3"><i class="fa fa-check"></i><b>7.3.1</b> Exercise set 7-3</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="intervals.html"><a href="intervals.html#frequentist-inference-ii-alternative-hypotheses-and-the-rejection-framework"><i class="fa fa-check"></i><b>7.4</b> Frequentist inference II: alternative hypotheses and the rejection framework</a><ul>
<li class="chapter" data-level="7.4.1" data-path="intervals.html"><a href="intervals.html#exercise-set-7-4"><i class="fa fa-check"></i><b>7.4.1</b> Exercise set 7-4</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="intervals.html"><a href="intervals.html#connecting-hypothesis-tests-and-confidence-intervals"><i class="fa fa-check"></i><b>7.5</b> Connecting hypothesis tests and confidence intervals</a></li>
<li class="chapter" data-level="7.6" data-path="intervals.html"><a href="intervals.html#nhst-and-the-abuse-of-tests"><i class="fa fa-check"></i><b>7.6</b> NHST and the abuse of tests</a><ul>
<li class="chapter" data-level="7.6.1" data-path="intervals.html"><a href="intervals.html#exercise-set-7-5"><i class="fa fa-check"></i><b>7.6.1</b> Exercise set 7-5</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="intervals.html"><a href="intervals.html#frequentist-inference-iii-power"><i class="fa fa-check"></i><b>7.7</b> Frequentist inference III: power</a><ul>
<li class="chapter" data-level="7.7.1" data-path="intervals.html"><a href="intervals.html#exercise-set-7-6"><i class="fa fa-check"></i><b>7.7.1</b> Exercise set 7-6</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="intervals.html"><a href="intervals.html#putting-it-together-what-happens-when-the-sample-size-increases"><i class="fa fa-check"></i><b>7.8</b> Putting it together: what happens when the sample size increases?</a></li>
<li class="chapter" data-level="7.9" data-path="intervals.html"><a href="intervals.html#chapter-summary"><i class="fa fa-check"></i><b>7.9</b> Chapter summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="semiparametric.html"><a href="semiparametric.html"><i class="fa fa-check"></i><b>8</b> Semiparametric estimation and inference</a><ul>
<li class="chapter" data-level="8.0.1" data-path="semiparametric.html"><a href="semiparametric.html#exercise-set-8-1"><i class="fa fa-check"></i><b>8.0.1</b> Exercise set 8-1</a></li>
<li class="chapter" data-level="8.1" data-path="semiparametric.html"><a href="semiparametric.html#semiparametric-point-estimation-using-the-method-of-moments"><i class="fa fa-check"></i><b>8.1</b> Semiparametric point estimation using the method of moments</a><ul>
<li class="chapter" data-level="8.1.1" data-path="semiparametric.html"><a href="semiparametric.html#introduction-to-moments"><i class="fa fa-check"></i><b>8.1.1</b> Introduction to moments</a></li>
<li class="chapter" data-level="8.1.2" data-path="semiparametric.html"><a href="semiparametric.html#plug-in-estimators"><i class="fa fa-check"></i><b>8.1.2</b> Plug-in estimators</a></li>
<li class="chapter" data-level="8.1.3" data-path="semiparametric.html"><a href="semiparametric.html#exercise-set-8-2"><i class="fa fa-check"></i><b>8.1.3</b> Exercise set 8-2</a></li>
<li class="chapter" data-level="8.1.4" data-path="semiparametric.html"><a href="semiparametric.html#the-method-of-moments"><i class="fa fa-check"></i><b>8.1.4</b> The method of moments</a></li>
<li class="chapter" data-level="8.1.5" data-path="semiparametric.html"><a href="semiparametric.html#exercise-set-8-3"><i class="fa fa-check"></i><b>8.1.5</b> Exercise set 8-3</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="semiparametric.html"><a href="semiparametric.html#semiparametric-interval-estimation-using-the-bootstrap"><i class="fa fa-check"></i><b>8.2</b> Semiparametric interval estimation using the bootstrap</a><ul>
<li class="chapter" data-level="8.2.1" data-path="semiparametric.html"><a href="semiparametric.html#exercise-set-8-4"><i class="fa fa-check"></i><b>8.2.1</b> Exercise set 8-4</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="semiparametric.html"><a href="semiparametric.html#semiparametric-hypothesis-testing-using-permutation-tests"><i class="fa fa-check"></i><b>8.3</b> Semiparametric hypothesis testing using permutation tests</a><ul>
<li class="chapter" data-level="8.3.1" data-path="semiparametric.html"><a href="semiparametric.html#exercise-set-8-5"><i class="fa fa-check"></i><b>8.3.1</b> Exercise set 8-5</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="semiparametric.html"><a href="semiparametric.html#chapter-summary-1"><i class="fa fa-check"></i><b>8.4</b> Chapter summary</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes on Statistical Thinking from Scratch</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="semiparametric" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Semiparametric estimation and inference</h1>
<blockquote>
<p>Parametric: governed by parameters; e.g., normal distributions</p>
</blockquote>
<blockquote>
<p>Nonparametric: not governed by parameters; used when we cannot assume that the distribution of a random variable follows a particular probability distribution</p>
</blockquote>
<blockquote>
<p>Semiparametric: a model whose behavior is partially governed by parameters</p>
</blockquote>
<blockquote>
<p>Empirical distribution function: summarizes all the information that the data provide about a random variable’s distribution</p>
</blockquote>
<p>The empirical distribution function <span class="math inline">\(\hat{F}_n(z)\)</span> gives the proportion of <em>observations in a sample</em> that are less than or equal to a constant <span class="math inline">\(z\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\hat{F}_n(z) =&amp; \frac{1}{n} \sum_{i = 1}^n I_{X_i \leq z}
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(I\)</span> is an indicator variable that states whether observation <span class="math inline">\(X_i\)</span> is less than or equal to <span class="math inline">\(z\)</span>.</p>
<div id="exercise-set-8-1" class="section level3">
<h3><span class="header-section-number">8.0.1</span> Exercise set 8-1</h3>
<ol style="list-style-type: decimal">
<li>Comparing an ECDF with a CDF for the normal distribution</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>As the sample size increases, the ECDF approximates the CDF of the normal distribution.</li>
</ol>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1">n &lt;-<span class="st"> </span><span class="dv">500</span></a>
<a class="sourceLine" id="cb1-2" title="2">x.vals &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dt">length.out =</span> <span class="dv">10000</span>)</a>
<a class="sourceLine" id="cb1-3" title="3">Fx &lt;-<span class="st"> </span><span class="kw">pnorm</span>(x.vals, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1-4" title="4"><span class="kw">plot</span>(x.vals, Fx, <span class="dt">xlab =</span> <span class="st">&quot;z&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;F(z)&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</a>
<a class="sourceLine" id="cb1-5" title="5">x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1-6" title="6"><span class="kw">lines</span>(<span class="kw">ecdf</span>(x), <span class="dt">verticals =</span> <span class="ot">TRUE</span>, <span class="dt">do.points =</span> <span class="ot">FALSE</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</a></code></pre></div>
<p><img src="08_semiparametric-estimation_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Comparing an ECDF with a CDF for the Poisson distribution</li>
</ol>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" title="1"><span class="kw">set.seed</span>(<span class="dv">22</span>)</a>
<a class="sourceLine" id="cb2-2" title="2">n &lt;-<span class="st"> </span><span class="dv">30</span></a>
<a class="sourceLine" id="cb2-3" title="3">lambda &lt;-<span class="st"> </span><span class="dv">10</span></a>
<a class="sourceLine" id="cb2-4" title="4">x.vals &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">30</span>, <span class="dt">by =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb2-5" title="5">Fx &lt;-<span class="st"> </span><span class="kw">ppois</span>(x.vals, <span class="dt">lambda =</span> lambda)</a>
<a class="sourceLine" id="cb2-6" title="6"><span class="kw">plot</span>(x.vals, Fx, <span class="dt">xlab =</span> <span class="st">&quot;z&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;F(z)&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;p&quot;</span>)</a>
<a class="sourceLine" id="cb2-7" title="7">x &lt;-<span class="st"> </span><span class="kw">rpois</span>(n, <span class="dt">lambda =</span> lambda)</a>
<a class="sourceLine" id="cb2-8" title="8"><span class="kw">lines</span>(<span class="kw">ecdf</span>(x), <span class="dt">verticals =</span> <span class="ot">TRUE</span>, <span class="dt">do.points =</span> <span class="ot">FALSE</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</a></code></pre></div>
<p><img src="08_semiparametric-estimation_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<ol start="2" style="list-style-type: decimal">
<li>See handwritten notes.</li>
</ol>
</div>
<div id="semiparametric-point-estimation-using-the-method-of-moments" class="section level2">
<h2><span class="header-section-number">8.1</span> Semiparametric point estimation using the method of moments</h2>
<div id="introduction-to-moments" class="section level3">
<h3><span class="header-section-number">8.1.1</span> Introduction to moments</h3>
<blockquote>
<p>Methods of moments: a semiparametric approach to estimation<br />
Method of maximum likelihood: a parametric approach to estimation</p>
</blockquote>
<p>Suppose <span class="math inline">\(X\)</span> is a random variable. The <span class="math inline">\(j\)</span>th <strong>moment</strong> of the distribution is:</p>
<p><span class="math display">\[
\begin{aligned}
\mu_j =&amp; E(X^j)
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is used as the symbol for a moment. For example <span class="math inline">\(\mu_1 = E(X)\)</span>. It is easy to express the first moment of <span class="math inline">\(X\)</span> as an expression using <span class="math inline">\(X\)</span> - but what about <span class="math inline">\(\mu_2\)</span>?</p>
<p><span class="math display">\[
\begin{aligned}
\mu_2 =&amp; E(X^2)
\end{aligned}
\]</span></p>
<p>Now we have expressed the second moment, <span class="math inline">\(\mu_2\)</span>, as the expectation of a new random variable, <span class="math inline">\(X^2\)</span>. At least this is how I interpret it. From my reading, I gather this is not so satisfying, because the second moment is then usually rearranged in the following way.</p>
<p>First, we need to recall the definition of Var(<span class="math inline">\(X\)</span>):</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{Var}(X) = \text{E}(X^2) - [\text{E}(X)]^2 \\
\end{aligned}
\]</span></p>
<p>So, if we rearrange we get:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}(X^2) = \text{Var}(X) + [\text{E}(X)]^2 \\
\end{aligned}
\]</span></p>
<p>We can continue on with 3rd, 4th, 5th, etc, moments. But expressing these in terms of <span class="math inline">\(X\)</span> is, I am guessing, a harder challenge. These additional moments describe further the probability distribution, but typically knowing the first and second moments is enough for practical purposes (our purposes). As an aside, the third moment gives us the <em>skewness</em>, and the fourth moment gives us the <em>kurtosis</em>, of the distribution. Finally, it is worth noting the notation for <em>a moment</em> - here I have used <span class="math inline">\(\mu\)</span>, becuase it is often used in statistics notes (that I found online). This can be confusing, because we often use <span class="math inline">\(\mu\)</span> for the population mean. But we won’t do that here, for clarity.</p>
<p>So, let us say that <span class="math inline">\(X\)</span> follows a Normal(<span class="math inline">\(\theta\)</span>, <span class="math inline">\(\sigma^2\)</span>) distribution. In this case, we know that E(<span class="math inline">\(X\)</span>) = <span class="math inline">\(\theta\)</span>, and that Var(<span class="math inline">\(X\)</span>) = <span class="math inline">\(\sigma^2\)</span>. So we can express the first and second moments as:</p>
<p><span class="math display">\[ 
\begin{aligned}
\mu_1 =&amp; ~ \text{E}(X) \\
=&amp; ~ \theta \\
\mu_2 =&amp; ~ \text{E}(X^2) \\
=&amp; \text{Var}(X) + [\text{E}(X)]^2 \\
=&amp; ~ \sigma^2 + \theta^2 \\
\end{aligned}
\]</span></p>
<p>So we have expressed the moments in terms of the parameters of the distribution we are trying estimate. We can rearrange these, to express the <em>parameters</em> in terms of <span class="math inline">\(X\)</span> - which is exactly what we want to do, since we are trying to estimate <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\sigma^2\)</span>!</p>
<p><span class="math display">\[ 
\begin{aligned}
\theta =&amp; ~ \text{E}(X) \\
\sigma^2 =&amp; ~ \text{E}(X^2) - [\text{E}(X)]^2 \\
\end{aligned}
\]</span></p>
<p>To paraphrase Edge, we can estimate the moments of arbitrary distributions (i.e., distributions that are not described by parameters) by following these steps:</p>
<ol style="list-style-type: decimal">
<li><p>Write the equations that give the moments of a random variable in terms of the parameters being estimated</p></li>
<li><p>Solve the equations from (1) for the desired parameters, giving expressions for the parameters in terms of the moments</p></li>
<li><p>Estimate the moments and plug the estimates into the expressions for the parameters from (2)</p></li>
</ol>
</div>
<div id="plug-in-estimators" class="section level3">
<h3><span class="header-section-number">8.1.2</span> Plug-in estimators</h3>
<blockquote>
<p>Plug-in estimation: perhaps I’m oversimplifying here, but this sounds like awesome jargon for ‘calculate your estimator from data’. In other words, if you want the population mean - collect some data and calculate the mean. Then ‘plug that in’ to your population mean.</p>
</blockquote>
<p>We can express a plug-in estimator of the <span class="math inline">\(k\)</span>th moment of <span class="math inline">\(X\)</span>, E(<span class="math inline">\(X^j\)</span>) as the <span class="math inline">\(k\)</span>th <em>sample moment</em>:</p>
<p><span class="math display">\[ 
\begin{aligned}
\overline{X^k} = \frac{1}{n} \sum_{i = 1}^n X_i^k
\end{aligned}
\]</span></p>
<p>So to recap: a <em>moment</em> describes the random variable <span class="math inline">\(X\)</span>. A <em>sample moment</em> is an estimate of the moment using independent samples (<span class="math inline">\(X_1, X_2, X_3\)</span>) drawn from <span class="math inline">\(X\)</span>.</p>
</div>
<div id="exercise-set-8-2" class="section level3">
<h3><span class="header-section-number">8.1.3</span> Exercise set 8-2</h3>
<ol style="list-style-type: decimal">
<li>Supose <span class="math inline">\(X_1, X_2, ..., X_n\)</span> are I.I.D observations.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>What is the plug-in estimator of the variance of <span class="math inline">\(X\)</span>?</li>
</ol>
<p><span class="math display">\[ 
\begin{aligned}
\sigma^2 =&amp; ~ \text{E}(X^2) - [\text{E}(X)]^2 \\
\hat\sigma^2 =&amp; ~ \frac{1}{n} \sum_{i = 1}^n X_i^2 - [\frac{1}{n} \sum_{i = 1}^n X_i]^2 \\
\end{aligned}
\]</span>
b. What is the plug-in estimator for the standard deviation of <span class="math inline">\(X\)</span>?</p>
<p><span class="math display">\[ 
\begin{aligned}
\hat\sigma =&amp; ~ \sqrt{\frac{1}{n} \sum_{i = 1}^n X_i^2 - [\frac{1}{n} \sum_{i = 1}^n X_i]^2} \\
\end{aligned}
\]</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>What is the plug-in estimator of the covariance of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>?</li>
</ol>
<p>Here is the formula for the covariance, as a reminder:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Cov}(X,Y) =&amp; ~ \text{E}([X - \text{E}(X)][Y - \text{E}(Y)]) \\
                =&amp; ~ \text{E}(XY) - \text{E}(X)\text{E}(Y)
\end{aligned}
\]</span>
Let’s use the 2nd equation:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Cov}(X,Y) =&amp; ~ \frac{1}{n} \sum_{i = 1}^n X_iY_i - [\frac{1}{n} \sum_{i = 1}^n X_i][\frac{1}{n} \sum_{i = 1}^n Y_i] \\
\end{aligned}
\]</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>What is the plug-in estimator of the correlation of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>?</li>
</ol>
<p>Here is the formula for the correlation, as a reminder:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Cor}(X,Y) =&amp; ~ \rho_{X,Y} \\
                =&amp; ~ \frac{\text{Cov}(X,Y)}{\sqrt{\text{Var}(X)\text{Var}(Y)}} \\
                =&amp; ~ \frac{\text{Cov}(X,Y)}{\sigma_X \sigma_Y}\\
\end{aligned}
\]</span></p>
<p>Plugging in, we get:</p>
<p><span class="math display">\[
\begin{aligned}
\rho_{X,Y}      =&amp; ~ \frac {\frac{1}{n} \sum_{i = 1}^n X_iY_i - 
                                  [\frac{1}{n} \sum_{i = 1}^n X_i][\frac{1}{n} \sum_{i = 1}^n Y_i]}  
                           {\sqrt{
                                  \frac{1}{n} \sum_{i = 1}^n X_i^2 - 
                                  [\frac{1}{n} \sum_{i = 1}^n X_i]^2}]
                                  [\frac{1}{n} \sum_{i = 1}^n Y_i^2]
                                  } \\
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Though the plug-in estimator of the variance is consistent, it is biased downward.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Demonstrate the downward bias in R with simulations.</li>
</ol>
<p>This is what I did first:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" title="1">n_obs &lt;-<span class="st"> </span><span class="dv">5</span></a>
<a class="sourceLine" id="cb3-2" title="2">n_sims &lt;-<span class="st"> </span><span class="dv">10000</span></a>
<a class="sourceLine" id="cb3-3" title="3"><span class="kw">set.seed</span>(<span class="dv">1010</span>)</a>
<a class="sourceLine" id="cb3-4" title="4">x &lt;-<span class="st"> </span><span class="kw">mat.samps</span>(<span class="dt">n =</span> n_obs, <span class="dt">nsim =</span> n_sims)</a>
<a class="sourceLine" id="cb3-5" title="5">x_var &lt;-<span class="st"> </span><span class="kw">apply</span>(<span class="dt">X =</span> x, <span class="dt">MARGIN =</span> <span class="dv">1</span>, <span class="dt">FUN =</span> var)</a>
<a class="sourceLine" id="cb3-6" title="6"><span class="kw">mean</span>(x_var)</a></code></pre></div>
<pre><code>## [1] 1.004699</code></pre>
<p>The result is very close to 1. This surprised me, given that I was expecting something below 1. So I ran Edge’s code, and in it, he defines a function to calculate the variance himself.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" title="1">var.pi &lt;-<span class="st"> </span><span class="cf">function</span>(vec){</a>
<a class="sourceLine" id="cb5-2" title="2">  <span class="kw">return</span>(<span class="kw">sum</span>((vec<span class="op">-</span><span class="kw">mean</span>(vec))<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="kw">length</span>(vec))</a>
<a class="sourceLine" id="cb5-3" title="3">}</a>
<a class="sourceLine" id="cb5-4" title="4">vars.pi &lt;-<span class="st"> </span><span class="kw">apply</span>(x, <span class="dv">1</span>, var.pi)</a>
<a class="sourceLine" id="cb5-5" title="5"><span class="kw">mean</span>(vars.pi)</a></code></pre></div>
<pre><code>## [1] 0.8037593</code></pre>
<p>Why the difference? Turns out this is a great demonstration of something I had read some time ago, and then buried away because it frankly was not super relevant. Let’s inspect the help function for <code>var</code>:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" title="1">?var</a></code></pre></div>
<p>And in the details you’ll see this note:</p>
<blockquote>
<p>The denominator n - 1 is used which gives an unbiased estimator of the (co)variance for i.i.d. observations. These functions return NA when there is only one observation (whereas S-PLUS has been returning NaN), and fail if x has length zero.</p>
</blockquote>
<p>Thanks to this book, this statement make sense. Let’s calculate the variance using <em>n</em> and <em>n-1</em> as the denominator:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" title="1">vec &lt;-<span class="st"> </span>x[<span class="dv">1</span>,]</a>
<a class="sourceLine" id="cb8-2" title="2">vec</a></code></pre></div>
<pre><code>## [1]  0.4974519  1.1826813  1.0876947 -1.3540474 -0.9988671</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" title="1"><span class="co"># Default function to calculate the variance in R</span></a>
<a class="sourceLine" id="cb10-2" title="2"><span class="kw">var</span>(vec)</a></code></pre></div>
<pre><code>## [1] 1.406506</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" title="1"><span class="co"># Edge&#39;s function, with the denominator of n</span></a>
<a class="sourceLine" id="cb12-2" title="2"><span class="kw">var.pi</span>(vec)</a></code></pre></div>
<pre><code>## [1] 1.125205</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" title="1"><span class="co"># Beating a dead horse:</span></a>
<a class="sourceLine" id="cb14-2" title="2"><span class="kw">sum</span>((vec<span class="op">-</span><span class="kw">mean</span>(vec))<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>(<span class="kw">length</span>(vec)) </a></code></pre></div>
<pre><code>## [1] 1.125205</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" title="1"><span class="co"># But now we change the denominator from n, to n-1</span></a>
<a class="sourceLine" id="cb16-2" title="2"><span class="co"># Unbiased estimator for the variance </span></a>
<a class="sourceLine" id="cb16-3" title="3"><span class="co"># Gives the same result as `var`</span></a>
<a class="sourceLine" id="cb16-4" title="4"><span class="kw">sum</span>((vec<span class="op">-</span><span class="kw">mean</span>(vec))<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>(<span class="kw">length</span>(vec) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) </a></code></pre></div>
<pre><code>## [1] 1.406506</code></pre>
<p>I have not read ahead, but I suspect Edge will discuss this discrepancy soon..</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Repeating the simulation, but with samples sizes from 2 to 10.</li>
</ol>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" title="1">n_sims &lt;-<span class="st"> </span><span class="dv">10000</span></a>
<a class="sourceLine" id="cb18-2" title="2">n_vec &lt;-<span class="st"> </span><span class="dv">2</span><span class="op">:</span><span class="dv">10</span></a>
<a class="sourceLine" id="cb18-3" title="3">variance_vec &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="dt">length =</span> <span class="kw">length</span>(n_vec))</a>
<a class="sourceLine" id="cb18-4" title="4"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(n_vec)){</a>
<a class="sourceLine" id="cb18-5" title="5">  n_obs &lt;-<span class="st"> </span>n_vec[i]</a>
<a class="sourceLine" id="cb18-6" title="6">  x &lt;-<span class="st"> </span><span class="kw">mat.samps</span>(<span class="dt">n =</span> n_obs, <span class="dt">nsim =</span> n_sims)</a>
<a class="sourceLine" id="cb18-7" title="7">  vars.pi &lt;-<span class="st"> </span><span class="kw">apply</span>(x, <span class="dv">1</span>, var.pi)</a>
<a class="sourceLine" id="cb18-8" title="8">  variance_vec[i] &lt;-<span class="st"> </span><span class="kw">mean</span>(vars.pi)</a>
<a class="sourceLine" id="cb18-9" title="9">}</a>
<a class="sourceLine" id="cb18-10" title="10">variance_vec </a></code></pre></div>
<pre><code>## [1] 0.4879436 0.6578587 0.7378372 0.7852684 0.8369602 0.8502939 0.8715858
## [8] 0.8900192 0.9012010</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" title="1"><span class="kw">plot</span>(n_vec, variance_vec, <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>, </a>
<a class="sourceLine" id="cb20-2" title="2">     <span class="dt">xlab =</span> <span class="st">&quot;Number of samples&quot;</span>, </a>
<a class="sourceLine" id="cb20-3" title="3">     <span class="dt">ylab =</span> <span class="st">&quot;Mean variance&quot;</span>, </a>
<a class="sourceLine" id="cb20-4" title="4">     <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))</a>
<a class="sourceLine" id="cb20-5" title="5"><span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">1</span>, <span class="dt">lty =</span> <span class="dv">2</span> , <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<p><img src="08_semiparametric-estimation_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>The bias is largest with a sample size of 2, and the plug-in estimator gets closer to the true value with increasing sample size.</p>
<p>I did not think to convert these decimal outputs to fractions as indicated in Edge’s solution, even having stumbled upon the unbiased estimator above. So this result is not yet intuitive:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}(\hat\sigma^2_n) =&amp; ~ \frac{n - 1}{n} \sigma^2 \\
\end{aligned}
\]</span></p>
<p>This equation demonstrates the bias of the plug-in estimator for the variance. If we multiply it by <span class="math inline">\(n/(n-1)\)</span>, we get the sample variance (<span class="math inline">\(s^2\)</span>), an unbiased estimator:</p>
<p><span class="math display">\[ 
\begin{aligned}
s^2 =&amp; ~ \frac{\sum_{i = 1}^n (X_i - \overline X_i)^2}{n - 1} \\
\end{aligned}
\]</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>See Edge solution. It explains how we get the expectation of the plug-in estimator.</li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li>Did not try.</li>
</ol>
</div>
<div id="the-method-of-moments" class="section level3">
<h3><span class="header-section-number">8.1.4</span> The method of moments</h3>
<p>We apply the method of moments to the model for simple linear regresion:</p>
<p><span class="math display">\[
\begin{aligned}
Y = \alpha + \beta X + \epsilon \\
\end{aligned}
\]</span></p>
<p>If we make the assumption that the expectation of the disturbance term is 0 for <em>all</em> values of <span class="math inline">\(X\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\text{E}(\epsilon | X = x) =&amp; ~ 0 \\
\end{aligned}
\]</span></p>
<p>then the conditional expectation of <span class="math inline">\(Y\)</span>, given any <span class="math inline">\(x\)</span>, can be predicted using a line with a slope <span class="math inline">\(\beta\)</span> and intercept <span class="math inline">\(\alpha\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\text{E}(Y) = \alpha + \beta_{\mu_X} \\
\end{aligned}
\]</span></p>
<p>If this assumption is not true, then the relationship between X and Y is not linear! Now that we have made the linearity assumption (see Edge’s Figure 8-4), we can proceed with the MOM estimators for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>.</p>
<p>We know that the covariance of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Cov}(X,Y) = \beta \sigma_X^2 \\
\end{aligned}
\]</span></p>
<p>and that:</p>
<p><span class="math display">\[
\begin{aligned}
\mu_X =&amp; ~ \text{E}(X) \\
\sigma_X^2 =&amp; ~ \text{Var}(X) \\
\text{Cov}(X,Y) =&amp; ~ \text{E}(XY) - \text{E}(X)\text{E}(Y) \\
\text{Var}(X) =&amp; ~ \text{E}(X^2) - [\text{E}(X)]^2 \\
\end{aligned}
\]</span></p>
<p>we can get expressions for the parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> in terms of the moments of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\alpha =&amp; ~ \text{E}(Y) - \beta \text{E}(X) \\
\beta =&amp; ~ \frac{\text{Cov}(X,Y)}{\sigma_X^2} \\
      =&amp; \frac{\text{E}(XY) - \text{E}(X)\text{E}(Y)}{\text{E}(X^2) - [\text{E}(X)]^2} \\
\end{aligned}
\]</span></p>
<p>The expression for <span class="math inline">\(\beta\)</span> is entirely in terms of moments, as opposed to the expression for <span class="math inline">\(\alpha\)</span>. So we’ll plug in sample moments for the moments in the expression for <span class="math inline">\(\beta\)</span>, multiply the numerator and denominator by <span class="math inline">\(\frac{n}{n}\)</span>, and get:</p>
<p><span class="math display">\[
\begin{aligned}
\tilde{\beta} =&amp; \frac{\sum X_i Y_i - \frac{1}{n} (\sum X_i) (\sum Y_i)}
                      {\sum X_i^2 - \frac{1}{n} (\sum X_i)^2 }\\
\end{aligned}
\]</span></p>
<p>(try working through the algebra to get this expression yourself).</p>
<p>Here’s the expression for <span class="math inline">\(\alpha\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\tilde{\alpha} =&amp; ~ \frac{1}{n} \sum Y_i - \tilde{\beta} \frac{1}{n} \sum X_i \\
               =&amp; ~ \frac{\sum Y_i - \tilde{\beta} \sum X_i} {n}
\end{aligned}
\]</span></p>
<p>These expressions are essentially identical to the expressions for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> that we derived for the coefficients of the least squares line in chapter 3.</p>
</div>
<div id="exercise-set-8-3" class="section level3">
<h3><span class="header-section-number">8.1.5</span> Exercise set 8-3</h3>
<ol style="list-style-type: decimal">
<li><p>See solution on paper.</p></li>
<li><p>See solution in Edge.</p></li>
</ol>
</div>
</div>
<div id="semiparametric-interval-estimation-using-the-bootstrap" class="section level2">
<h2><span class="header-section-number">8.2</span> Semiparametric interval estimation using the bootstrap</h2>
<div id="exercise-set-8-4" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Exercise set 8-4</h3>
</div>
</div>
<div id="semiparametric-hypothesis-testing-using-permutation-tests" class="section level2">
<h2><span class="header-section-number">8.3</span> Semiparametric hypothesis testing using permutation tests</h2>
<div id="exercise-set-8-5" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Exercise set 8-5</h3>
</div>
</div>
<div id="chapter-summary-1" class="section level2">
<h2><span class="header-section-number">8.4</span> Chapter summary</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intervals.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
