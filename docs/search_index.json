[
["index.html", "Notes on Statistical Thinking from Scratch Preface", " Notes on Statistical Thinking from Scratch Robin Elahi 2020-03-20 Preface This project is a set of notes for Statistical Thinking from Scratch, by M.D. Edge. My personal goal is to become more comfortable with the nitty gritty underlying the statistical tools I commonly use - essentially, regression. Edge takes a unique approach in that he takes a small dataset, and dissects regression ‘from scratch’. Each of these bookdown chapters corresponds to each of Edge’s 10 book chapters. The impetus for this bookdown project was the cancellation of my spring 2020 course Experimental Design and Probability due to the coronavirus pandemic. So, I’ll be filling in some gaps in my stats toolkit and learning how to use bookdown. The stfs package can be installed from Github: install.packages(&quot;devtools&quot;) library(devtools) install_github(&quot;mdedge/stfspack&quot;) library(stfspack) As Edge points out in his Prelude, the typical introductory course in biological statistics (including my own) revolves around learning a series of tests: t-tests, regression, ANOVA . In STFS, the focus instead is on one procedure - simple linear regression - and takes ‘little for granted’ (translation: we’ll be working through the math, lightly). The primary dataset consists of 11 observations. To heck with big data. The chapters will work through the following: 1. Probability 2. Estimation (using data to guess the values that describe a data generating process) 3. Inference (testing hypotheses about the processes that might have generated an observed dataset) What is a data generating process? This wikipedia entry is not all that helpful, aside from the fact that it highlights the difficulty in defining this term. For now, let’s just think of the DGP as a set of rules (e.g., a deterministic equation) plus ‘noise’ that allows us to describe a set of obervations (i.e., data). How to publish a bookdown project on github https://community.rstudio.com/t/hosting-bookdown-in-github/20427 http://seankross.com/2016/11/17/How-to-Start-a-Bookdown-Book.html "],
["intro.html", "Chapter 1 Introduction", " Chapter 1 Introduction library(stfspack) library(tidyverse) theme_set(theme_bw(base_size = 12) + theme(strip.background = element_blank(), panel.grid = element_blank())) Figure 1.1 shows data on the amount of fertilizer applied to cropland (x-axis), and the cereal yields (y-axis), for each of 11 countries in Africa. There is a positive relationship, but is it strong? Is it weak? How are we to reason about these data? anscombe %&gt;% ggplot(aes(x1, y1)) + geom_point() + labs(x = &quot;Fertilizer consumption (kg/hectare)&quot;, y = &quot;Cereal yield (100kg/hectare)&quot;) Figure 1.1: Fertilizer consumption and cereal yield in 11 sub-Saharan African countries Statistics, that’s how! Statistics allows us to reason from data, and rests on a mathematical framework. It is worth understanding, even minimally, this framework. That’s why we are reading this book. Chapter 1 provides an overview of simple linear regression, which allows us to identify a line that ‘best’ fits the data. We can use the lm() function in R to fit a simple linear regression: mod.fit &lt;- lm(y1 ~ x1, data = anscombe) anscombe %&gt;% ggplot(aes(x1, y1)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + labs(x = &quot;Fertilizer consumption (kg/hectare)&quot;, y = &quot;Cereal yield (100kg/hectare)&quot;) Figure 1.2: The agriculture data with a line of best fit from the simple linear regression summary(mod.fit) ## ## Call: ## lm(formula = y1 ~ x1, data = anscombe) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.92127 -0.45577 -0.04136 0.70941 1.83882 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.0001 1.1247 2.667 0.02573 * ## x1 0.5001 0.1179 4.241 0.00217 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.237 on 9 degrees of freedom ## Multiple R-squared: 0.6665, Adjusted R-squared: 0.6295 ## F-statistic: 17.99 on 1 and 9 DF, p-value: 0.00217 What do the following columns in the ‘Coefficients’ table refer to? the Estimates: (Intercept) and x1 Std. Error Pr(&gt;|t|) How do each of these relate to the ideas of estimation and inference? A cautionary tale Next we fit a different set of (fake) data, that give the exact same regression results: mod.fit2 &lt;- lm(y3 ~ x3, data = anscombe) anscombe %&gt;% ggplot(aes(x3, y3)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + labs(x = &quot;Fertilizer consumption (kg/hectare)&quot;, y = &quot;Cereal yield (100kg/hectare)&quot;) Figure 1.3: The data underlying the analysis of the variables y3 and x3 in the anscombe data set Yes, you can run another regression model, but you should treat the results of the table with suspicion, given the figure above. summary(mod.fit2) ## ## Call: ## lm(formula = y3 ~ x3, data = anscombe) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.1586 -0.6146 -0.2303 0.1540 3.2411 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.0025 1.1245 2.670 0.02562 * ## x3 0.4997 0.1179 4.239 0.00218 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.236 on 9 degrees of freedom ## Multiple R-squared: 0.6663, Adjusted R-squared: 0.6292 ## F-statistic: 17.97 on 1 and 9 DF, p-value: 0.002176 The rest of the book will give us the foundation to interpret all of the values in the regression table, and the underlying assumptions of the linear model. "]
]
