[
["bayesian.html", "Chapter 10 Bayesian estimation and inference 10.1 How to choose a prior distribution? 10.2 The unscaled posterior, conjugacy, and sampling from the posterior 10.3 Bayesian point estimation using Bayes estimators 10.4 Bayesian interval estimation using credible intervals 10.5 Bayesian ‘hypothesis testing’ using Bayes factors 10.6 Conclusion: Bayesian vs. frequentist methods 10.7 Chapter summary", " Chapter 10 Bayesian estimation and inference Parameters Frequentist view: parameters are fixed Bayesian view: parameter are random Posterior distribution: the probability distribution of the parameter(s) being estimated, given the data observed Prior distribution: the probability distribution function used to ‘describe’ the parameter(s) before any data are observed If we have a prior, we can calculate the posterior \\(f(\\theta | D = d)\\) as follows: \\[ \\begin{aligned} f(\\theta | D = d) =&amp; ~ \\frac{f_D(d|\\theta) ~ f_{\\theta}(\\theta)} {f_D(d)} \\\\ \\end{aligned} \\] where the likelihood \\(f_D(d|\\theta)\\) is multiplied by the prior \\(f_{\\theta}(\\theta)\\) in the numerator, which is divided by the probability of the data \\(f_D(d)\\). The probability of the data is the probability of observing the data given the parameter, averaged across all parameter values weighted by the probability (or density) of each parameter value: \\[ \\begin{aligned} f_D(d) =&amp; ~ \\int_{-\\infty}^{\\infty} f_D(d|\\theta) f_{\\theta}(\\theta) d\\theta\\\\ \\end{aligned} \\] 10.1 How to choose a prior distribution? 10.2 The unscaled posterior, conjugacy, and sampling from the posterior 10.2.1 Exercise set 10-1 n &lt;- 20 true.mean &lt;- 2 known.sd &lt;- 1 prior.mean &lt;- 0 prior.sd &lt;- 1 set.seed(8675309) z &lt;- rnorm(n,true.mean,known.sd) mean(z) ## [1] 2.149314 hist(z) post.conj.norm.norm &lt;- function(z, known.sd, prior.mean, prior.sd){ xbar &lt;- mean(z) post.expec &lt;- (prior.mean / prior.sd^2 + xbar*length(z) / known.sd^2)/(1 / prior.sd^2 + length(z) / known.sd^2) post.var &lt;- 1 / (1 / prior.sd^2 + length(z) / known.sd^2) list(&quot;posterior.expectation&quot; = post.expec, &quot;posterior.variance&quot; = post.var) } post.conj.norm.norm(z, known.sd, prior.mean, prior.sd) ## $posterior.expectation ## [1] 2.046966 ## ## $posterior.variance ## [1] 0.04761905 library(MCMCpack) mn.mod &lt;- MCnormalnormal(z, sigma2 = 1, mu0 = prior.mean, tau20 = prior.sd^2, mc = 10000) summary(mn.mod) ## ## Iterations = 1:10000 ## Thinning interval = 1 ## Number of chains = 1 ## Sample size per chain = 10000 ## ## 1. Empirical mean and standard deviation for each variable, ## plus standard error of the mean: ## ## Mean SD Naive SE Time-series SE ## 2.046645 0.219418 0.002194 0.002308 ## ## 2. Quantiles for each variable: ## ## 2.5% 25% 50% 75% 97.5% ## 1.614 1.897 2.045 2.194 2.476 10.3 Bayesian point estimation using Bayes estimators 10.3.1 Exercise set 10-2 10.4 Bayesian interval estimation using credible intervals 10.4.1 Exercise set 10-3 10.5 Bayesian ‘hypothesis testing’ using Bayes factors 10.5.1 Exercise set 10-4 10.6 Conclusion: Bayesian vs. frequentist methods 10.7 Chapter summary "]
]
