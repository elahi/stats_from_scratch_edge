<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Bayesian estimation and inference | Notes on Statistical Thinking from Scratch</title>
  <meta name="description" content="Cliff notes for Statistical Thinking from Scratch, by Doc Edge." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Bayesian estimation and inference | Notes on Statistical Thinking from Scratch" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Cliff notes for Statistical Thinking from Scratch, by Doc Edge." />
  <meta name="github-repo" content="elahi/stats_from_scratch_edge" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Bayesian estimation and inference | Notes on Statistical Thinking from Scratch" />
  
  <meta name="twitter:description" content="Cliff notes for Statistical Thinking from Scratch, by Doc Edge." />
  

<meta name="author" content="Robin Elahi" />


<meta name="date" content="2020-09-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="parametric.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-121894527-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-121894527-4');
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notes on Statistical Thinking from Scratch</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="r-eda.html"><a href="r-eda.html"><i class="fa fa-check"></i><b>2</b> R and exploratory data analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="r-eda.html"><a href="r-eda.html#inspecting-the-dataframe"><i class="fa fa-check"></i><b>2.1</b> Inspecting the dataframe</a></li>
<li class="chapter" data-level="2.2" data-path="r-eda.html"><a href="r-eda.html#histograms"><i class="fa fa-check"></i><b>2.2</b> Histograms</a></li>
<li class="chapter" data-level="2.3" data-path="r-eda.html"><a href="r-eda.html#summarising-data"><i class="fa fa-check"></i><b>2.3</b> Summarising data</a></li>
<li class="chapter" data-level="2.4" data-path="r-eda.html"><a href="r-eda.html#loops"><i class="fa fa-check"></i><b>2.4</b> Loops</a></li>
<li class="chapter" data-level="2.5" data-path="r-eda.html"><a href="r-eda.html#functions"><i class="fa fa-check"></i><b>2.5</b> Functions</a></li>
<li class="chapter" data-level="2.6" data-path="r-eda.html"><a href="r-eda.html#boxplots"><i class="fa fa-check"></i><b>2.6</b> Boxplots</a></li>
<li class="chapter" data-level="2.7" data-path="r-eda.html"><a href="r-eda.html#scatterplots"><i class="fa fa-check"></i><b>2.7</b> Scatterplots</a></li>
<li class="chapter" data-level="2.8" data-path="r-eda.html"><a href="r-eda.html#exercise-set-2-2"><i class="fa fa-check"></i><b>2.8</b> Exercise set 2-2</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="best-fit-line.html"><a href="best-fit-line.html"><i class="fa fa-check"></i><b>3</b> Line of best fit</a><ul>
<li class="chapter" data-level="3.1" data-path="best-fit-line.html"><a href="best-fit-line.html#exercise-set-3-1"><i class="fa fa-check"></i><b>3.1</b> Exercise set 3-1</a></li>
<li class="chapter" data-level="3.2" data-path="best-fit-line.html"><a href="best-fit-line.html#exercise-set-3-2"><i class="fa fa-check"></i><b>3.2</b> Exercise set 3-2</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>4</b> Probability and random variables</a><ul>
<li class="chapter" data-level="4.0.1" data-path="probability.html"><a href="probability.html#probability-vs-estimation"><i class="fa fa-check"></i><b>4.0.1</b> Probability vs estimation</a></li>
<li class="chapter" data-level="4.0.2" data-path="probability.html"><a href="probability.html#what-is-a-probability"><i class="fa fa-check"></i><b>4.0.2</b> What is a probability?</a></li>
<li class="chapter" data-level="4.0.3" data-path="probability.html"><a href="probability.html#set-notation"><i class="fa fa-check"></i><b>4.0.3</b> Set notation</a></li>
<li class="chapter" data-level="4.1" data-path="probability.html"><a href="probability.html#kolmogorovs-three-axioms-of-probability"><i class="fa fa-check"></i><b>4.1</b> Kolmogorov’s three axioms of probability</a><ul>
<li class="chapter" data-level="4.1.1" data-path="probability.html"><a href="probability.html#exercise-set-4-1"><i class="fa fa-check"></i><b>4.1.1</b> Exercise set 4-1</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="probability.html"><a href="probability.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>4.2</b> Conditional probability and independence</a><ul>
<li class="chapter" data-level="4.2.1" data-path="probability.html"><a href="probability.html#exercise-set-4-2"><i class="fa fa-check"></i><b>4.2.1</b> Exercise set 4-2</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="probability.html"><a href="probability.html#bayes-theorem"><i class="fa fa-check"></i><b>4.3</b> Bayes’ Theorem</a></li>
<li class="chapter" data-level="4.4" data-path="probability.html"><a href="probability.html#discrete-random-variables-and-distributions"><i class="fa fa-check"></i><b>4.4</b> Discrete random variables and distributions</a><ul>
<li class="chapter" data-level="4.4.1" data-path="probability.html"><a href="probability.html#exercise-set-4-3"><i class="fa fa-check"></i><b>4.4.1</b> Exercise set 4-3</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="probability.html"><a href="probability.html#continuous-random-variables-and-distributions"><i class="fa fa-check"></i><b>4.5</b> Continuous random variables and distributions</a><ul>
<li class="chapter" data-level="4.5.1" data-path="probability.html"><a href="probability.html#exercise-set-4-4"><i class="fa fa-check"></i><b>4.5.1</b> Exercise set 4-4</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="probability.html"><a href="probability.html#probability-density-functions"><i class="fa fa-check"></i><b>4.6</b> Probability density functions</a><ul>
<li class="chapter" data-level="4.6.1" data-path="probability.html"><a href="probability.html#additional-viz"><i class="fa fa-check"></i><b>4.6.1</b> Additional viz</a></li>
<li class="chapter" data-level="4.6.2" data-path="probability.html"><a href="probability.html#exercise-set-4-5"><i class="fa fa-check"></i><b>4.6.2</b> Exercise set 4-5</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="probability.html"><a href="probability.html#families-of-distributions"><i class="fa fa-check"></i><b>4.7</b> Families of distributions</a><ul>
<li class="chapter" data-level="4.7.1" data-path="probability.html"><a href="probability.html#exercise-set-4-6"><i class="fa fa-check"></i><b>4.7.1</b> Exercise set 4-6</a></li>
<li class="chapter" data-level="4.7.2" data-path="probability.html"><a href="probability.html#additional-exercise"><i class="fa fa-check"></i><b>4.7.2</b> Additional exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="randomvars.html"><a href="randomvars.html"><i class="fa fa-check"></i><b>5</b> Properties of random variables</a><ul>
<li class="chapter" data-level="5.1" data-path="randomvars.html"><a href="randomvars.html#expected-values-and-the-law-of-large-numbers"><i class="fa fa-check"></i><b>5.1</b> Expected values and the law of large numbers</a><ul>
<li class="chapter" data-level="5.1.1" data-path="randomvars.html"><a href="randomvars.html#weak-law-of-large-numbers"><i class="fa fa-check"></i><b>5.1.1</b> Weak law of large numbers</a></li>
<li class="chapter" data-level="5.1.2" data-path="randomvars.html"><a href="randomvars.html#handy-facts-about-expectations"><i class="fa fa-check"></i><b>5.1.2</b> Handy facts about expectations</a></li>
<li class="chapter" data-level="5.1.3" data-path="randomvars.html"><a href="randomvars.html#exercise-set-5-1"><i class="fa fa-check"></i><b>5.1.3</b> Exercise set 5-1</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="randomvars.html"><a href="randomvars.html#variance-and-standard-deviation"><i class="fa fa-check"></i><b>5.2</b> Variance and standard deviation</a><ul>
<li class="chapter" data-level="5.2.1" data-path="randomvars.html"><a href="randomvars.html#beautiful-properties-of-the-variance"><i class="fa fa-check"></i><b>5.2.1</b> Beautiful properties of the variance</a></li>
<li class="chapter" data-level="5.2.2" data-path="randomvars.html"><a href="randomvars.html#exercise-set-5-2"><i class="fa fa-check"></i><b>5.2.2</b> Exercise set 5-2</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="randomvars.html"><a href="randomvars.html#joint-distributions-covariance-and-correlation"><i class="fa fa-check"></i><b>5.3</b> Joint distributions, covariance, and correlation</a><ul>
<li class="chapter" data-level="5.3.1" data-path="randomvars.html"><a href="randomvars.html#joint-probability-distributions"><i class="fa fa-check"></i><b>5.3.1</b> Joint probability distributions</a></li>
<li class="chapter" data-level="5.3.2" data-path="randomvars.html"><a href="randomvars.html#marginal-distributions"><i class="fa fa-check"></i><b>5.3.2</b> Marginal distributions</a></li>
<li class="chapter" data-level="5.3.3" data-path="randomvars.html"><a href="randomvars.html#covariance"><i class="fa fa-check"></i><b>5.3.3</b> Covariance</a></li>
<li class="chapter" data-level="5.3.4" data-path="randomvars.html"><a href="randomvars.html#correlation"><i class="fa fa-check"></i><b>5.3.4</b> Correlation</a></li>
<li class="chapter" data-level="5.3.5" data-path="probability.html"><a href="probability.html#additional-exercise"><i class="fa fa-check"></i><b>5.3.5</b> Additional exercise</a></li>
<li class="chapter" data-level="5.3.6" data-path="randomvars.html"><a href="randomvars.html#exercise-set-5-3"><i class="fa fa-check"></i><b>5.3.6</b> Exercise set 5-3</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="randomvars.html"><a href="randomvars.html#conditional-distribution-expectation-variance"><i class="fa fa-check"></i><b>5.4</b> Conditional distribution, expectation, variance</a></li>
<li class="chapter" data-level="5.5" data-path="randomvars.html"><a href="randomvars.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>5.5</b> The central limit theorem</a><ul>
<li class="chapter" data-level="5.5.1" data-path="randomvars.html"><a href="randomvars.html#exercise-set-5-4"><i class="fa fa-check"></i><b>5.5.1</b> Exercise set 5-4</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="randomvars.html"><a href="randomvars.html#a-probabilistic-model-for-simple-linear-regression"><i class="fa fa-check"></i><b>5.6</b> A probabilistic model for simple linear regression</a><ul>
<li class="chapter" data-level="5.6.1" data-path="randomvars.html"><a href="randomvars.html#assumptions-of-the-linear-model"><i class="fa fa-check"></i><b>5.6.1</b> Assumptions of the linear model</a></li>
<li class="chapter" data-level="5.6.2" data-path="randomvars.html"><a href="randomvars.html#important-claims-that-follow-from-these-assumptions"><i class="fa fa-check"></i><b>5.6.2</b> Important claims that follow from these assumptions</a></li>
<li class="chapter" data-level="5.6.3" data-path="randomvars.html"><a href="randomvars.html#checking-these-assumptions"><i class="fa fa-check"></i><b>5.6.3</b> Checking these assumptions</a></li>
<li class="chapter" data-level="5.6.4" data-path="randomvars.html"><a href="randomvars.html#exercise-set-5-5"><i class="fa fa-check"></i><b>5.6.4</b> Exercise set 5-5</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="estimators.html"><a href="estimators.html"><i class="fa fa-check"></i><b>6</b> Properties of point estimators</a><ul>
<li class="chapter" data-level="6.1" data-path="estimators.html"><a href="estimators.html#bias"><i class="fa fa-check"></i><b>6.1</b> Bias</a><ul>
<li class="chapter" data-level="6.1.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-1"><i class="fa fa-check"></i><b>6.1.1</b> Exercise set 6-1</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="estimators.html"><a href="estimators.html#variance"><i class="fa fa-check"></i><b>6.2</b> Variance</a><ul>
<li class="chapter" data-level="6.2.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-2"><i class="fa fa-check"></i><b>6.2.1</b> Exercise set 6-2</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="estimators.html"><a href="estimators.html#mean-squared-error"><i class="fa fa-check"></i><b>6.3</b> Mean squared error</a><ul>
<li class="chapter" data-level="6.3.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-3"><i class="fa fa-check"></i><b>6.3.1</b> Exercise set 6-3</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="estimators.html"><a href="estimators.html#consistency"><i class="fa fa-check"></i><b>6.4</b> Consistency</a><ul>
<li class="chapter" data-level="6.4.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-4"><i class="fa fa-check"></i><b>6.4.1</b> Exercise set 6-4</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="estimators.html"><a href="estimators.html#efficiency"><i class="fa fa-check"></i><b>6.5</b> Efficiency</a><ul>
<li class="chapter" data-level="6.5.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-5"><i class="fa fa-check"></i><b>6.5.1</b> Exercise set 6-5</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="estimators.html"><a href="estimators.html#statistical-decision-theory-and-risk"><i class="fa fa-check"></i><b>6.6</b> Statistical decision theory and risk</a></li>
<li class="chapter" data-level="6.7" data-path="estimators.html"><a href="estimators.html#robustness"><i class="fa fa-check"></i><b>6.7</b> Robustness</a><ul>
<li class="chapter" data-level="6.7.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-8"><i class="fa fa-check"></i><b>6.7.1</b> Exercise set 6-8</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="estimators.html"><a href="estimators.html#estimators-for-simple-linear-regression"><i class="fa fa-check"></i><b>6.8</b> Estimators for simple linear regression</a><ul>
<li class="chapter" data-level="6.8.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-9"><i class="fa fa-check"></i><b>6.8.1</b> Exercise set 6-9</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="intervals.html"><a href="intervals.html"><i class="fa fa-check"></i><b>7</b> Interval estimation and inference</a><ul>
<li class="chapter" data-level="7.1" data-path="intervals.html"><a href="intervals.html#standard-error"><i class="fa fa-check"></i><b>7.1</b> Standard error</a><ul>
<li class="chapter" data-level="7.1.1" data-path="intervals.html"><a href="intervals.html#exercise-set-7-1"><i class="fa fa-check"></i><b>7.1.1</b> Exercise set 7-1</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="intervals.html"><a href="intervals.html#confidence-intervals"><i class="fa fa-check"></i><b>7.2</b> Confidence intervals</a><ul>
<li class="chapter" data-level="7.2.1" data-path="intervals.html"><a href="intervals.html#exercise-set-7-2"><i class="fa fa-check"></i><b>7.2.1</b> Exercise set 7-2</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="intervals.html"><a href="intervals.html#frequentist-inference-i-null-hypotheses-test-statistics-and-p-values"><i class="fa fa-check"></i><b>7.3</b> Frequentist inference I: null hypotheses, test statistics, and <em>p</em> values</a><ul>
<li class="chapter" data-level="7.3.1" data-path="intervals.html"><a href="intervals.html#exercise-set-7-3"><i class="fa fa-check"></i><b>7.3.1</b> Exercise set 7-3</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="intervals.html"><a href="intervals.html#frequentist-inference-ii-alternative-hypotheses-and-the-rejection-framework"><i class="fa fa-check"></i><b>7.4</b> Frequentist inference II: alternative hypotheses and the rejection framework</a><ul>
<li class="chapter" data-level="7.4.1" data-path="intervals.html"><a href="intervals.html#exercise-set-7-4"><i class="fa fa-check"></i><b>7.4.1</b> Exercise set 7-4</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="intervals.html"><a href="intervals.html#connecting-hypothesis-tests-and-confidence-intervals"><i class="fa fa-check"></i><b>7.5</b> Connecting hypothesis tests and confidence intervals</a></li>
<li class="chapter" data-level="7.6" data-path="intervals.html"><a href="intervals.html#nhst-and-the-abuse-of-tests"><i class="fa fa-check"></i><b>7.6</b> NHST and the abuse of tests</a><ul>
<li class="chapter" data-level="7.6.1" data-path="intervals.html"><a href="intervals.html#exercise-set-7-5"><i class="fa fa-check"></i><b>7.6.1</b> Exercise set 7-5</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="intervals.html"><a href="intervals.html#frequentist-inference-iii-power"><i class="fa fa-check"></i><b>7.7</b> Frequentist inference III: power</a><ul>
<li class="chapter" data-level="7.7.1" data-path="intervals.html"><a href="intervals.html#exercise-set-7-6"><i class="fa fa-check"></i><b>7.7.1</b> Exercise set 7-6</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="intervals.html"><a href="intervals.html#putting-it-together-what-happens-when-the-sample-size-increases"><i class="fa fa-check"></i><b>7.8</b> Putting it together: what happens when the sample size increases?</a></li>
<li class="chapter" data-level="7.9" data-path="intervals.html"><a href="intervals.html#chapter-summary"><i class="fa fa-check"></i><b>7.9</b> Chapter summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="semiparametric.html"><a href="semiparametric.html"><i class="fa fa-check"></i><b>8</b> Semiparametric estimation and inference</a><ul>
<li class="chapter" data-level="8.0.1" data-path="semiparametric.html"><a href="semiparametric.html#exercise-set-8-1"><i class="fa fa-check"></i><b>8.0.1</b> Exercise set 8-1</a></li>
<li class="chapter" data-level="8.1" data-path="semiparametric.html"><a href="semiparametric.html#semiparametric-point-estimation-using-the-method-of-moments"><i class="fa fa-check"></i><b>8.1</b> Semiparametric point estimation using the method of moments</a><ul>
<li class="chapter" data-level="8.1.1" data-path="semiparametric.html"><a href="semiparametric.html#introduction-to-moments"><i class="fa fa-check"></i><b>8.1.1</b> Introduction to moments</a></li>
<li class="chapter" data-level="8.1.2" data-path="semiparametric.html"><a href="semiparametric.html#plug-in-estimators"><i class="fa fa-check"></i><b>8.1.2</b> Plug-in estimators</a></li>
<li class="chapter" data-level="8.1.3" data-path="semiparametric.html"><a href="semiparametric.html#exercise-set-8-2"><i class="fa fa-check"></i><b>8.1.3</b> Exercise set 8-2</a></li>
<li class="chapter" data-level="8.1.4" data-path="semiparametric.html"><a href="semiparametric.html#the-method-of-moments"><i class="fa fa-check"></i><b>8.1.4</b> The method of moments</a></li>
<li class="chapter" data-level="8.1.5" data-path="semiparametric.html"><a href="semiparametric.html#exercise-set-8-3"><i class="fa fa-check"></i><b>8.1.5</b> Exercise set 8-3</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="semiparametric.html"><a href="semiparametric.html#semiparametric-interval-estimation-using-the-bootstrap"><i class="fa fa-check"></i><b>8.2</b> Semiparametric interval estimation using the bootstrap</a><ul>
<li class="chapter" data-level="8.2.1" data-path="semiparametric.html"><a href="semiparametric.html#exercise-set-8-4"><i class="fa fa-check"></i><b>8.2.1</b> Exercise set 8-4</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="semiparametric.html"><a href="semiparametric.html#semiparametric-hypothesis-testing-using-permutation-tests"><i class="fa fa-check"></i><b>8.3</b> Semiparametric hypothesis testing using permutation tests</a><ul>
<li class="chapter" data-level="8.3.1" data-path="semiparametric.html"><a href="semiparametric.html#exercise-set-8-5"><i class="fa fa-check"></i><b>8.3.1</b> Exercise set 8-5</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="intervals.html"><a href="intervals.html#chapter-summary"><i class="fa fa-check"></i><b>8.4</b> Chapter summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="parametric.html"><a href="parametric.html"><i class="fa fa-check"></i><b>9</b> Parametric estimation and inference</a><ul>
<li class="chapter" data-level="9.0.1" data-path="parametric.html"><a href="parametric.html#exercise-set-9-1"><i class="fa fa-check"></i><b>9.0.1</b> Exercise set 9-1</a></li>
<li class="chapter" data-level="9.1" data-path="parametric.html"><a href="parametric.html#parametric-estimation-using-maximum-likelihood"><i class="fa fa-check"></i><b>9.1</b> Parametric estimation using maximum likelihood</a><ul>
<li class="chapter" data-level="9.1.1" data-path="parametric.html"><a href="parametric.html#exercise-set-9-2"><i class="fa fa-check"></i><b>9.1.1</b> Exercise set 9-2</a></li>
<li class="chapter" data-level="9.1.2" data-path="parametric.html"><a href="parametric.html#maximum-likelihood-estimation-for-simple-linear-regression"><i class="fa fa-check"></i><b>9.1.2</b> Maximum-likelihood estimation for simple linear regression</a></li>
<li class="chapter" data-level="9.1.3" data-path="parametric.html"><a href="parametric.html#exercise-set-9-3"><i class="fa fa-check"></i><b>9.1.3</b> Exercise set 9-3</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="parametric.html"><a href="parametric.html#parametric-interval-estimation-the-direct-approach-and-fisher-information"><i class="fa fa-check"></i><b>9.2</b> Parametric interval estimation: the direct approach and Fisher information</a><ul>
<li class="chapter" data-level="9.2.1" data-path="parametric.html"><a href="parametric.html#exercise-set-9-4"><i class="fa fa-check"></i><b>9.2.1</b> Exercise set 9-4</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="parametric.html"><a href="parametric.html#parametric-hypothesis-testing-using-the-wald-test"><i class="fa fa-check"></i><b>9.3</b> Parametric hypothesis testing using the Wald test</a><ul>
<li class="chapter" data-level="9.3.1" data-path="parametric.html"><a href="parametric.html#wald-test"><i class="fa fa-check"></i><b>9.3.1</b> Wald test</a></li>
<li class="chapter" data-level="9.3.2" data-path="parametric.html"><a href="parametric.html#exercise-set-9-5"><i class="fa fa-check"></i><b>9.3.2</b> Exercise set 9-5</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="parametric.html"><a href="parametric.html#parametric-hypothesis-testing-using-the-likelihood-ratio-test"><i class="fa fa-check"></i><b>9.4</b> Parametric hypothesis testing using the likelihood-ratio test</a><ul>
<li class="chapter" data-level="9.4.1" data-path="parametric.html"><a href="parametric.html#exercise-set-9-6"><i class="fa fa-check"></i><b>9.4.1</b> Exercise set 9-6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="bayesian.html"><a href="bayesian.html"><i class="fa fa-check"></i><b>10</b> Bayesian estimation and inference</a><ul>
<li class="chapter" data-level="10.1" data-path="bayesian.html"><a href="bayesian.html#how-to-choose-a-prior-distribution"><i class="fa fa-check"></i><b>10.1</b> How to choose a prior distribution?</a></li>
<li class="chapter" data-level="10.2" data-path="bayesian.html"><a href="bayesian.html#the-unscaled-posterior-conjugacy-and-sampling-from-the-posterior"><i class="fa fa-check"></i><b>10.2</b> The unscaled posterior, conjugacy, and sampling from the posterior</a><ul>
<li class="chapter" data-level="10.2.1" data-path="bayesian.html"><a href="bayesian.html#rejection-sampling-algorithm"><i class="fa fa-check"></i><b>10.2.1</b> Rejection sampling algorithm</a></li>
<li class="chapter" data-level="10.2.2" data-path="bayesian.html"><a href="bayesian.html#exercise-set-10-1"><i class="fa fa-check"></i><b>10.2.2</b> Exercise set 10-1</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="bayesian.html"><a href="bayesian.html#bayesian-point-estimation-using-bayes-estimators"><i class="fa fa-check"></i><b>10.3</b> Bayesian point estimation using Bayes estimators</a><ul>
<li class="chapter" data-level="10.3.1" data-path="bayesian.html"><a href="bayesian.html#exercise-set-10-2"><i class="fa fa-check"></i><b>10.3.1</b> Exercise set 10-2</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="bayesian.html"><a href="bayesian.html#bayesian-interval-estimation-using-credible-intervals"><i class="fa fa-check"></i><b>10.4</b> Bayesian interval estimation using credible intervals</a><ul>
<li class="chapter" data-level="10.4.1" data-path="bayesian.html"><a href="bayesian.html#exercise-set-10-3"><i class="fa fa-check"></i><b>10.4.1</b> Exercise set 10-3</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="bayesian.html"><a href="bayesian.html#bayesian-hypothesis-testing-using-bayes-factors"><i class="fa fa-check"></i><b>10.5</b> Bayesian ‘hypothesis testing’ using Bayes factors</a><ul>
<li class="chapter" data-level="10.5.1" data-path="bayesian.html"><a href="bayesian.html#exercise-set-10-4"><i class="fa fa-check"></i><b>10.5.1</b> Exercise set 10-4</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="bayesian.html"><a href="bayesian.html#conclusion-bayesian-vs.-frequentist-methods"><i class="fa fa-check"></i><b>10.6</b> Conclusion: Bayesian vs. frequentist methods</a></li>
<li class="chapter" data-level="10.7" data-path="intervals.html"><a href="intervals.html#chapter-summary"><i class="fa fa-check"></i><b>10.7</b> Chapter summary</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes on Statistical Thinking from Scratch</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bayesian" class="section level1">
<h1><span class="header-section-number">Chapter 10</span> Bayesian estimation and inference</h1>
<p>Parameters</p>
<ul>
<li>Frequentist view: parameters are fixed</li>
<li>Bayesian view: parameter are random</li>
</ul>
<blockquote>
<p>Posterior distribution: the probability distribution of the parameter(s) being estimated, given the data observed</p>
</blockquote>
<blockquote>
<p>Prior distribution: the probability distribution function used to ‘describe’ the parameter(s) before any data are observed</p>
</blockquote>
<p>If we have a prior, we can calculate the posterior <span class="math inline">\(f(\theta | D = d)\)</span> as follows:</p>
<p><span class="math display">\[
\begin{aligned}
f(\theta | D = d) =&amp; ~ \frac{f_D(d|\theta) ~ f_{\theta}(\theta)} {f_D(d)} \\
\end{aligned}
\]</span>
where the likelihood <span class="math inline">\(f_D(d|\theta)\)</span> is multiplied by the prior <span class="math inline">\(f_{\theta}(\theta)\)</span> in the numerator, which is divided by the probability of the data <span class="math inline">\(f_D(d)\)</span>. The probability of the data is the probability of observing the data given the parameter, averaged across all parameter values weighted by the probability (or density) of each parameter value:</p>
<p><span class="math display">\[
\begin{aligned}
f_D(d) =&amp; ~ \int_{-\infty}^{\infty} f_D(d|\theta) f_{\theta}(\theta) d\theta\\
\end{aligned}
\]</span></p>
<div id="how-to-choose-a-prior-distribution" class="section level2">
<h2><span class="header-section-number">10.1</span> How to choose a prior distribution?</h2>
</div>
<div id="the-unscaled-posterior-conjugacy-and-sampling-from-the-posterior" class="section level2">
<h2><span class="header-section-number">10.2</span> The unscaled posterior, conjugacy, and sampling from the posterior</h2>
<div id="rejection-sampling-algorithm" class="section level3">
<h3><span class="header-section-number">10.2.1</span> Rejection sampling algorithm</h3>
<ol style="list-style-type: decimal">
<li><p>Sample an observation <span class="math inline">\(\theta^*\)</span> from the prior distribution.</p></li>
<li><p>Compute <span class="math inline">\(m\)</span>, the quotient of the unscaled posterior divided by the prior at <span class="math inline">\(\theta^*\)</span>:</p></li>
</ol>
<p><span class="math display">\[
\begin{aligned}
m =&amp; ~ \frac{f_D(d|\theta^*) ~ f_{\theta}(\theta^*)} {f_{\theta}(\theta^*)} \\
  =&amp; ~ f_D(d|\theta^*) \\ 
  =&amp; ~ L(\theta^* | d)
\end{aligned}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li><p>Independently, sample a random variable X from a continuous distribution.</p></li>
<li><p>If X m, then “accept” <span class="math inline">\(\theta^*\)</span> as an observation from the posterior distribution and save its value. Otherwise “reject” <span class="math inline">\(\theta^*\)</span> and discard it.</p></li>
<li><p>Repeat steps 1–4 until the desired number of simulated observations from the posterior distribution are gathered.</p></li>
</ol>
</div>
<div id="exercise-set-10-1" class="section level3">
<h3><span class="header-section-number">10.2.2</span> Exercise set 10-1</h3>
<ol style="list-style-type: decimal">
<li></li>
</ol>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="bayesian.html#cb1-1"></a>n &lt;-<span class="st"> </span><span class="dv">20</span></span>
<span id="cb1-2"><a href="bayesian.html#cb1-2"></a>true.mean &lt;-<span class="st"> </span><span class="dv">2</span></span>
<span id="cb1-3"><a href="bayesian.html#cb1-3"></a>known.sd &lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb1-4"><a href="bayesian.html#cb1-4"></a>prior.mean &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb1-5"><a href="bayesian.html#cb1-5"></a>prior.sd &lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb1-6"><a href="bayesian.html#cb1-6"></a><span class="kw">set.seed</span>(<span class="dv">8675309</span>)</span>
<span id="cb1-7"><a href="bayesian.html#cb1-7"></a>z &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n,true.mean,known.sd)</span>
<span id="cb1-8"><a href="bayesian.html#cb1-8"></a><span class="kw">mean</span>(z)</span></code></pre></div>
<pre><code>## [1] 2.149314</code></pre>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="bayesian.html#cb3-1"></a><span class="kw">hist</span>(z)</span></code></pre></div>
<p><img src="10_bayesian-estimation_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<ol style="list-style-type: lower-alpha">
<li>Edge’s function uses equations 10.4 and 10.5 to calculate the mean and variance of the posterior distribution, which we know is normal due to conjugacy (Normal prior <span class="math inline">\(\times\)</span> Normal likelihood = Normal posterior):</li>
</ol>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="bayesian.html#cb4-1"></a>post.conj.norm.norm &lt;-<span class="st"> </span><span class="cf">function</span>(z, known.sd, prior.mean, prior.sd){</span>
<span id="cb4-2"><a href="bayesian.html#cb4-2"></a>  xbar &lt;-<span class="st"> </span><span class="kw">mean</span>(z)</span>
<span id="cb4-3"><a href="bayesian.html#cb4-3"></a>  post.expec &lt;-<span class="st"> </span>(prior.mean <span class="op">/</span><span class="st"> </span>prior.sd<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>xbar<span class="op">*</span><span class="kw">length</span>(z) <span class="op">/</span></span>
<span id="cb4-4"><a href="bayesian.html#cb4-4"></a><span class="st">        </span>known.sd<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>(<span class="dv">1</span> <span class="op">/</span><span class="st">   </span>prior.sd<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="kw">length</span>(z) <span class="op">/</span><span class="st"> </span>known.sd<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb4-5"><a href="bayesian.html#cb4-5"></a>  post.var &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">/</span><span class="st">   </span>prior.sd<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="kw">length</span>(z) <span class="op">/</span><span class="st"> </span>known.sd<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb4-6"><a href="bayesian.html#cb4-6"></a>  <span class="kw">list</span>(<span class="st">&quot;posterior.expectation&quot;</span> =<span class="st"> </span>post.expec,</span>
<span id="cb4-7"><a href="bayesian.html#cb4-7"></a><span class="st">&quot;posterior.variance&quot;</span> =<span class="st"> </span>post.var)</span>
<span id="cb4-8"><a href="bayesian.html#cb4-8"></a>}</span>
<span id="cb4-9"><a href="bayesian.html#cb4-9"></a></span>
<span id="cb4-10"><a href="bayesian.html#cb4-10"></a>post_conjugate &lt;-<span class="st"> </span><span class="kw">post.conj.norm.norm</span>(z, known.sd, prior.mean, prior.sd)</span></code></pre></div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Using MCMC</li>
</ol>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="bayesian.html#cb5-1"></a><span class="kw">library</span>(MCMCpack)</span>
<span id="cb5-2"><a href="bayesian.html#cb5-2"></a>mn.mod &lt;-<span class="st"> </span><span class="kw">MCnormalnormal</span>(z, <span class="dt">sigma2 =</span> <span class="dv">1</span>, <span class="dt">mu0 =</span> prior.mean, <span class="dt">tau20 =</span> prior.sd<span class="op">^</span><span class="dv">2</span>, <span class="dt">mc =</span> <span class="dv">10000</span>)</span>
<span id="cb5-3"><a href="bayesian.html#cb5-3"></a><span class="kw">summary</span>(mn.mod) </span></code></pre></div>
<pre><code>## 
## Iterations = 1:10000
## Thinning interval = 1 
## Number of chains = 1 
## Sample size per chain = 10000 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##           Mean             SD       Naive SE Time-series SE 
##       2.046645       0.219418       0.002194       0.002308 
## 
## 2. Quantiles for each variable:
## 
##  2.5%   25%   50%   75% 97.5% 
## 1.614 1.897 2.045 2.194 2.476</code></pre>
<p>Let’s plot the MCMC results in a histogram, and overlaid with a normal distribution from the conjugate expression.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="bayesian.html#cb7-1"></a><span class="kw">hist</span>(mn.mod, <span class="dt">freq =</span> <span class="ot">FALSE</span>, <span class="dt">border =</span> <span class="st">&quot;white&quot;</span>)</span>
<span id="cb7-2"><a href="bayesian.html#cb7-2"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">4</span>, <span class="dt">length=</span><span class="dv">100</span>)</span>
<span id="cb7-3"><a href="bayesian.html#cb7-3"></a>hx &lt;-<span class="st"> </span><span class="kw">dnorm</span>(x, <span class="dt">mean =</span> post_conjugate<span class="op">$</span>posterior.expectation, <span class="dt">sd =</span> <span class="kw">sqrt</span>(post_conjugate<span class="op">$</span>posterior.variance))</span>
<span id="cb7-4"><a href="bayesian.html#cb7-4"></a><span class="kw">lines</span>(x, hx, <span class="dt">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="10_bayesian-estimation_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<ol start="2" style="list-style-type: decimal">
<li></li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>The ratio of the unscaled posterior to the prior is the likelihood.</p></li>
<li><p>See Edge.</p></li>
<li><p>We can adjust step 2 in the above algorithm by dividing the likelihood of <span class="math inline">\(\theta^*\)</span> by the maximum likelihood:</p></li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Compute <span class="math inline">\(m\)</span>, the quotient of the unscaled posterior divided by the prior at <span class="math inline">\(\theta^*\)</span>:</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
m =&amp; ~ \frac{L(\theta^* | d)} {\text{argmax} ~ L(\theta | d)} \\
\end{aligned}
\]</span>
d. Edge’s R function for rejection sampling</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="bayesian.html#cb8-1"></a><span class="co">#Get 1 sample under rejection sampling from normal with known sd.</span></span>
<span id="cb8-2"><a href="bayesian.html#cb8-2"></a><span class="co">#z is a vector of data.</span></span>
<span id="cb8-3"><a href="bayesian.html#cb8-3"></a>get.<span class="fl">1.</span>samp.norm &lt;-<span class="st"> </span><span class="cf">function</span>(z, <span class="dt">known.sd =</span> <span class="dv">1</span>, <span class="dt">prior.mean =</span> <span class="dv">0</span>, <span class="dt">prior.sd =</span> <span class="dv">1</span>){</span>
<span id="cb8-4"><a href="bayesian.html#cb8-4"></a>  accepted &lt;-<span class="st"> </span><span class="ot">FALSE</span></span>
<span id="cb8-5"><a href="bayesian.html#cb8-5"></a>  max.like &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">dnorm</span>(z, <span class="dt">mean =</span> <span class="kw">mean</span>(z), <span class="dt">sd =</span> known.sd)))) </span>
<span id="cb8-6"><a href="bayesian.html#cb8-6"></a>  <span class="cf">while</span>(accepted <span class="op">==</span><span class="st"> </span><span class="ot">FALSE</span>){</span>
<span id="cb8-7"><a href="bayesian.html#cb8-7"></a>    cand &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>, prior.mean, prior.sd)</span>
<span id="cb8-8"><a href="bayesian.html#cb8-8"></a>    like &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">dnorm</span>(z, <span class="dt">mean =</span> cand, <span class="dt">sd =</span> known.sd)))) </span>
<span id="cb8-9"><a href="bayesian.html#cb8-9"></a>    crit &lt;-<span class="st"> </span>like <span class="op">/</span><span class="st"> </span>max.like</span>
<span id="cb8-10"><a href="bayesian.html#cb8-10"></a>    xunif &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb8-11"><a href="bayesian.html#cb8-11"></a>    <span class="cf">if</span>(xunif <span class="op">&lt;=</span><span class="st"> </span>crit){accepted &lt;-<span class="st"> </span><span class="ot">TRUE</span>}</span>
<span id="cb8-12"><a href="bayesian.html#cb8-12"></a>  }</span>
<span id="cb8-13"><a href="bayesian.html#cb8-13"></a>  cand</span>
<span id="cb8-14"><a href="bayesian.html#cb8-14"></a>}</span>
<span id="cb8-15"><a href="bayesian.html#cb8-15"></a></span>
<span id="cb8-16"><a href="bayesian.html#cb8-16"></a><span class="co"># Wrapper for get.1.samp.norm() that gets rejection sample from posterior of desired size.</span></span>
<span id="cb8-17"><a href="bayesian.html#cb8-17"></a>reject.samp.norm &lt;-<span class="st"> </span><span class="cf">function</span>(z, <span class="dt">known.sd =</span> <span class="dv">1</span>, <span class="dt">prior.mean =</span> <span class="dv">0</span>, <span class="dt">prior.sd =</span> <span class="dv">1</span>, <span class="dt">nsamps =</span> <span class="dv">10000</span>){</span>
<span id="cb8-18"><a href="bayesian.html#cb8-18"></a>  samps &lt;-<span class="st"> </span><span class="kw">numeric</span>(nsamps)</span>
<span id="cb8-19"><a href="bayesian.html#cb8-19"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="kw">seq_along</span>(samps)){</span>
<span id="cb8-20"><a href="bayesian.html#cb8-20"></a>    samps[i] &lt;-<span class="st"> </span><span class="kw">get.1.samp.norm</span>(z, known.sd, prior.mean, prior.sd) }</span>
<span id="cb8-21"><a href="bayesian.html#cb8-21"></a>  samps }</span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="bayesian.html#cb9-1"></a><span class="co">#Get 1 sample under rejection sampling from normal with known sd, using unscaled likelihood</span></span>
<span id="cb9-2"><a href="bayesian.html#cb9-2"></a><span class="co">#z is a vector of data.</span></span>
<span id="cb9-3"><a href="bayesian.html#cb9-3"></a>get.<span class="fl">1.</span>samp.norm.unscaled &lt;-<span class="st"> </span><span class="cf">function</span>(z, <span class="dt">known.sd =</span> <span class="dv">1</span>, <span class="dt">prior.mean =</span> <span class="dv">0</span>, <span class="dt">prior.sd =</span> <span class="dv">1</span>){</span>
<span id="cb9-4"><a href="bayesian.html#cb9-4"></a>  accepted &lt;-<span class="st"> </span><span class="ot">FALSE</span></span>
<span id="cb9-5"><a href="bayesian.html#cb9-5"></a>  max.like &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">dnorm</span>(z, <span class="dt">mean =</span> <span class="kw">mean</span>(z), <span class="dt">sd =</span> known.sd)))) </span>
<span id="cb9-6"><a href="bayesian.html#cb9-6"></a>  <span class="cf">while</span>(accepted <span class="op">==</span><span class="st"> </span><span class="ot">FALSE</span>){</span>
<span id="cb9-7"><a href="bayesian.html#cb9-7"></a>    cand &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>, prior.mean, prior.sd)</span>
<span id="cb9-8"><a href="bayesian.html#cb9-8"></a>    like &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">sum</span>(<span class="kw">log</span>(<span class="kw">dnorm</span>(z, <span class="dt">mean =</span> cand, <span class="dt">sd =</span> known.sd)))) </span>
<span id="cb9-9"><a href="bayesian.html#cb9-9"></a>    crit &lt;-<span class="st"> </span>like <span class="co">#/ max.like</span></span>
<span id="cb9-10"><a href="bayesian.html#cb9-10"></a>    xunif &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb9-11"><a href="bayesian.html#cb9-11"></a>    <span class="cf">if</span>(xunif <span class="op">&lt;=</span><span class="st"> </span>crit){accepted &lt;-<span class="st"> </span><span class="ot">TRUE</span>}</span>
<span id="cb9-12"><a href="bayesian.html#cb9-12"></a>  }</span>
<span id="cb9-13"><a href="bayesian.html#cb9-13"></a>  cand</span>
<span id="cb9-14"><a href="bayesian.html#cb9-14"></a>}</span>
<span id="cb9-15"><a href="bayesian.html#cb9-15"></a></span>
<span id="cb9-16"><a href="bayesian.html#cb9-16"></a><span class="co"># Wrapper for get.1.samp.norm() that gets rejection sample from posterior of desired size.</span></span>
<span id="cb9-17"><a href="bayesian.html#cb9-17"></a>reject.samp.norm.unscaled &lt;-<span class="st"> </span><span class="cf">function</span>(z, <span class="dt">known.sd =</span> <span class="dv">1</span>, <span class="dt">prior.mean =</span> <span class="dv">0</span>, <span class="dt">prior.sd =</span> <span class="dv">1</span>, <span class="dt">nsamps =</span> <span class="dv">10000</span>){</span>
<span id="cb9-18"><a href="bayesian.html#cb9-18"></a>  samps &lt;-<span class="st"> </span><span class="kw">numeric</span>(nsamps)</span>
<span id="cb9-19"><a href="bayesian.html#cb9-19"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="kw">seq_along</span>(samps)){</span>
<span id="cb9-20"><a href="bayesian.html#cb9-20"></a>    samps[i] &lt;-<span class="st"> </span><span class="kw">get.1.samp.norm.unscaled</span>(z, known.sd, prior.mean, prior.sd) }</span>
<span id="cb9-21"><a href="bayesian.html#cb9-21"></a>  samps }</span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="bayesian.html#cb10-1"></a>post_rej &lt;-<span class="st"> </span><span class="kw">reject.samp.norm</span>(<span class="dt">z =</span> z, <span class="dt">known.sd =</span> known.sd, </span>
<span id="cb10-2"><a href="bayesian.html#cb10-2"></a>                             <span class="dt">prior.mean =</span> prior.mean, <span class="dt">prior.sd =</span> prior.sd, <span class="dt">nsamps =</span> <span class="dv">10000</span>)</span>
<span id="cb10-3"><a href="bayesian.html#cb10-3"></a><span class="co"># post_rej_unscaled &lt;- reject.samp.norm.unscaled(z = z, known.sd = known.sd, </span></span>
<span id="cb10-4"><a href="bayesian.html#cb10-4"></a><span class="co">#                              prior.mean = prior.mean, prior.sd = prior.sd, nsamps = 10000) # takes much longer</span></span></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="bayesian.html#cb11-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb11-2"><a href="bayesian.html#cb11-2"></a><span class="kw">hist</span>(mn.mod, <span class="dt">freq =</span> <span class="ot">FALSE</span>, <span class="dt">border =</span> <span class="st">&quot;white&quot;</span>)</span>
<span id="cb11-3"><a href="bayesian.html#cb11-3"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">4</span>, <span class="dt">length=</span><span class="dv">100</span>)</span>
<span id="cb11-4"><a href="bayesian.html#cb11-4"></a>pd_conjugate &lt;-<span class="st"> </span><span class="kw">dnorm</span>(x, <span class="dt">mean =</span> post_conjugate<span class="op">$</span>posterior.expectation, <span class="dt">sd =</span> <span class="kw">sqrt</span>(post_conjugate<span class="op">$</span>posterior.variance))</span>
<span id="cb11-5"><a href="bayesian.html#cb11-5"></a><span class="kw">lines</span>(x, pd_conjugate, <span class="dt">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb11-6"><a href="bayesian.html#cb11-6"></a></span>
<span id="cb11-7"><a href="bayesian.html#cb11-7"></a><span class="kw">hist</span>(post_rej, <span class="dt">freq =</span> <span class="ot">FALSE</span>, <span class="dt">border =</span> <span class="st">&quot;white&quot;</span>)</span>
<span id="cb11-8"><a href="bayesian.html#cb11-8"></a><span class="kw">lines</span>(x, pd_conjugate, <span class="dt">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="10_bayesian-estimation_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
</div>
<div id="bayesian-point-estimation-using-bayes-estimators" class="section level2">
<h2><span class="header-section-number">10.3</span> Bayesian point estimation using Bayes estimators</h2>
<p>The Bayesian approach to point estimation is to report a standard indicator of the posterior distribution’s central tendency: the posterior mean, median, or mode. These are Bayes estimators with appealing loss functions:</p>
<ul>
<li>Mean: minimizes squared error loss</li>
<li>Median: minimizes absolute error loss</li>
<li>Mode: minimizes zero-one loss</li>
</ul>
<p>See text for a more thorough explanation.</p>
<div id="exercise-set-10-2" class="section level3">
<h3><span class="header-section-number">10.3.1</span> Exercise set 10-2</h3>
<ol style="list-style-type: decimal">
<li></li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Fit model using maximum likelihood:</li>
</ol>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="bayesian.html#cb12-1"></a><span class="co">#library(arm)</span></span>
<span id="cb12-2"><a href="bayesian.html#cb12-2"></a>x &lt;-<span class="st"> </span>anscombe<span class="op">$</span>x1</span>
<span id="cb12-3"><a href="bayesian.html#cb12-3"></a>y &lt;-<span class="st"> </span>anscombe<span class="op">$</span>y1</span>
<span id="cb12-4"><a href="bayesian.html#cb12-4"></a>lm1 &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x)</span>
<span id="cb12-5"><a href="bayesian.html#cb12-5"></a><span class="kw">summary</span>(lm1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.92127 -0.45577 -0.04136  0.70941  1.83882 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)   3.0001     1.1247   2.667  0.02573 * 
## x             0.5001     0.1179   4.241  0.00217 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.237 on 9 degrees of freedom
## Multiple R-squared:  0.6665,	Adjusted R-squared:  0.6295 
## F-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217</code></pre>
<ol start="2" style="list-style-type: lower-alpha">
<li>Fit model using <code>MCMCregress</code>:</li>
</ol>
<p>b0: prior mean of Beta
B0: prior precision of Beta</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="bayesian.html#cb14-1"></a>b0 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb14-2"><a href="bayesian.html#cb14-2"></a>reg1 &lt;-<span class="st"> </span><span class="kw">MCMCregress</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">b0 =</span> b0, <span class="dt">B0 =</span> <span class="fl">0.0001</span>)</span>
<span id="cb14-3"><a href="bayesian.html#cb14-3"></a></span>
<span id="cb14-4"><a href="bayesian.html#cb14-4"></a>res1 &lt;-<span class="st"> </span><span class="kw">summary</span>(reg1)<span class="op">$</span>statistics[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb14-5"><a href="bayesian.html#cb14-5"></a><span class="st">  </span><span class="kw">as_tibble</span>(<span class="dt">rownames =</span> <span class="st">&quot;parameter&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb14-6"><a href="bayesian.html#cb14-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">precision =</span> <span class="fl">0.0001</span>)</span>
<span id="cb14-7"><a href="bayesian.html#cb14-7"></a></span>
<span id="cb14-8"><a href="bayesian.html#cb14-8"></a>reg2 &lt;-<span class="st"> </span><span class="kw">MCMCregress</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">b0 =</span> b0, <span class="dt">B0 =</span> <span class="dv">1</span>)</span>
<span id="cb14-9"><a href="bayesian.html#cb14-9"></a>res2 &lt;-<span class="st"> </span><span class="kw">summary</span>(reg2)<span class="op">$</span>statistics[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb14-10"><a href="bayesian.html#cb14-10"></a><span class="st">  </span><span class="kw">as_tibble</span>(<span class="dt">rownames =</span> <span class="st">&quot;parameter&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb14-11"><a href="bayesian.html#cb14-11"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">precision =</span> <span class="dv">1</span>)</span>
<span id="cb14-12"><a href="bayesian.html#cb14-12"></a></span>
<span id="cb14-13"><a href="bayesian.html#cb14-13"></a>reg3 &lt;-<span class="st"> </span><span class="kw">MCMCregress</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">b0 =</span> b0, <span class="dt">B0 =</span> <span class="dv">100</span>)</span>
<span id="cb14-14"><a href="bayesian.html#cb14-14"></a>res3 &lt;-<span class="st"> </span><span class="kw">summary</span>(reg3)<span class="op">$</span>statistics[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb14-15"><a href="bayesian.html#cb14-15"></a><span class="st">  </span><span class="kw">as_tibble</span>(<span class="dt">rownames =</span> <span class="st">&quot;parameter&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb14-16"><a href="bayesian.html#cb14-16"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">precision =</span> <span class="dv">100</span>)</span>
<span id="cb14-17"><a href="bayesian.html#cb14-17"></a></span>
<span id="cb14-18"><a href="bayesian.html#cb14-18"></a>df &lt;-<span class="st"> </span><span class="kw">rbind</span>(res1, res2, res3)</span>
<span id="cb14-19"><a href="bayesian.html#cb14-19"></a></span>
<span id="cb14-20"><a href="bayesian.html#cb14-20"></a>df <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb14-21"><a href="bayesian.html#cb14-21"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> precision, <span class="dt">y =</span> Mean)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb14-22"><a href="bayesian.html#cb14-22"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb14-23"><a href="bayesian.html#cb14-23"></a><span class="st">  </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Mean <span class="op">-</span><span class="st"> </span>SD, <span class="dt">ymax =</span> Mean <span class="op">+</span><span class="st"> </span>SD), <span class="dt">width =</span> <span class="dv">0</span>) <span class="op">+</span></span>
<span id="cb14-24"><a href="bayesian.html#cb14-24"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>parameter, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb14-25"><a href="bayesian.html#cb14-25"></a><span class="st">  </span><span class="kw">scale_x_log10</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb14-26"><a href="bayesian.html#cb14-26"></a><span class="st">  </span><span class="kw">coord_flip</span>()</span></code></pre></div>
<p><img src="10_bayesian-estimation_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="bayesian.html#cb15-1"></a>b0 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">0</span>)</span>
<span id="cb15-2"><a href="bayesian.html#cb15-2"></a>reg1 &lt;-<span class="st"> </span><span class="kw">MCMCregress</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">b0 =</span> b0, <span class="dt">B0 =</span> <span class="fl">0.0001</span>)</span>
<span id="cb15-3"><a href="bayesian.html#cb15-3"></a>res1 &lt;-<span class="st"> </span><span class="kw">summary</span>(reg1)<span class="op">$</span>statistics[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb15-4"><a href="bayesian.html#cb15-4"></a><span class="st">  </span><span class="kw">as_tibble</span>(<span class="dt">rownames =</span> <span class="st">&quot;parameter&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb15-5"><a href="bayesian.html#cb15-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">precision =</span> <span class="fl">0.0001</span>)</span>
<span id="cb15-6"><a href="bayesian.html#cb15-6"></a></span>
<span id="cb15-7"><a href="bayesian.html#cb15-7"></a>reg2 &lt;-<span class="st"> </span><span class="kw">MCMCregress</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">b0 =</span> b0, <span class="dt">B0 =</span> <span class="dv">1</span>)</span>
<span id="cb15-8"><a href="bayesian.html#cb15-8"></a>res2 &lt;-<span class="st"> </span><span class="kw">summary</span>(reg2)<span class="op">$</span>statistics[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb15-9"><a href="bayesian.html#cb15-9"></a><span class="st">  </span><span class="kw">as_tibble</span>(<span class="dt">rownames =</span> <span class="st">&quot;parameter&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb15-10"><a href="bayesian.html#cb15-10"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">precision =</span> <span class="dv">1</span>)</span>
<span id="cb15-11"><a href="bayesian.html#cb15-11"></a></span>
<span id="cb15-12"><a href="bayesian.html#cb15-12"></a>reg3 &lt;-<span class="st"> </span><span class="kw">MCMCregress</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">b0 =</span> b0, <span class="dt">B0 =</span> <span class="dv">100</span>)</span>
<span id="cb15-13"><a href="bayesian.html#cb15-13"></a>res3 &lt;-<span class="st"> </span><span class="kw">summary</span>(reg3)<span class="op">$</span>statistics[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb15-14"><a href="bayesian.html#cb15-14"></a><span class="st">  </span><span class="kw">as_tibble</span>(<span class="dt">rownames =</span> <span class="st">&quot;parameter&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb15-15"><a href="bayesian.html#cb15-15"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">precision =</span> <span class="dv">100</span>)</span>
<span id="cb15-16"><a href="bayesian.html#cb15-16"></a></span>
<span id="cb15-17"><a href="bayesian.html#cb15-17"></a>df &lt;-<span class="st"> </span><span class="kw">rbind</span>(res1, res2, res3)</span>
<span id="cb15-18"><a href="bayesian.html#cb15-18"></a></span>
<span id="cb15-19"><a href="bayesian.html#cb15-19"></a>df <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb15-20"><a href="bayesian.html#cb15-20"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> precision, <span class="dt">y =</span> Mean)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb15-21"><a href="bayesian.html#cb15-21"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb15-22"><a href="bayesian.html#cb15-22"></a><span class="st">  </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Mean <span class="op">-</span><span class="st"> </span>SD, <span class="dt">ymax =</span> Mean <span class="op">+</span><span class="st"> </span>SD), <span class="dt">width =</span> <span class="dv">0</span>) <span class="op">+</span></span>
<span id="cb15-23"><a href="bayesian.html#cb15-23"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>parameter, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb15-24"><a href="bayesian.html#cb15-24"></a><span class="st">  </span><span class="kw">scale_x_log10</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb15-25"><a href="bayesian.html#cb15-25"></a><span class="st">  </span><span class="kw">coord_flip</span>()</span></code></pre></div>
<p><img src="10_bayesian-estimation_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="bayesian.html#cb16-1"></a>b0 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">-5</span>)</span>
<span id="cb16-2"><a href="bayesian.html#cb16-2"></a>reg1 &lt;-<span class="st"> </span><span class="kw">MCMCregress</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">b0 =</span> b0, <span class="dt">B0 =</span> <span class="fl">0.0001</span>)</span>
<span id="cb16-3"><a href="bayesian.html#cb16-3"></a>res1 &lt;-<span class="st"> </span><span class="kw">summary</span>(reg1)<span class="op">$</span>statistics[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb16-4"><a href="bayesian.html#cb16-4"></a><span class="st">  </span><span class="kw">as_tibble</span>(<span class="dt">rownames =</span> <span class="st">&quot;parameter&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb16-5"><a href="bayesian.html#cb16-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">precision =</span> <span class="fl">0.0001</span>)</span>
<span id="cb16-6"><a href="bayesian.html#cb16-6"></a></span>
<span id="cb16-7"><a href="bayesian.html#cb16-7"></a>reg2 &lt;-<span class="st"> </span><span class="kw">MCMCregress</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">b0 =</span> b0, <span class="dt">B0 =</span> <span class="dv">1</span>)</span>
<span id="cb16-8"><a href="bayesian.html#cb16-8"></a>res2 &lt;-<span class="st"> </span><span class="kw">summary</span>(reg2)<span class="op">$</span>statistics[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb16-9"><a href="bayesian.html#cb16-9"></a><span class="st">  </span><span class="kw">as_tibble</span>(<span class="dt">rownames =</span> <span class="st">&quot;parameter&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb16-10"><a href="bayesian.html#cb16-10"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">precision =</span> <span class="dv">1</span>)</span>
<span id="cb16-11"><a href="bayesian.html#cb16-11"></a></span>
<span id="cb16-12"><a href="bayesian.html#cb16-12"></a>reg3 &lt;-<span class="st"> </span><span class="kw">MCMCregress</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">b0 =</span> b0, <span class="dt">B0 =</span> <span class="dv">100</span>)</span>
<span id="cb16-13"><a href="bayesian.html#cb16-13"></a>res3 &lt;-<span class="st"> </span><span class="kw">summary</span>(reg3)<span class="op">$</span>statistics[,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>] <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb16-14"><a href="bayesian.html#cb16-14"></a><span class="st">  </span><span class="kw">as_tibble</span>(<span class="dt">rownames =</span> <span class="st">&quot;parameter&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb16-15"><a href="bayesian.html#cb16-15"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">precision =</span> <span class="dv">100</span>)</span>
<span id="cb16-16"><a href="bayesian.html#cb16-16"></a></span>
<span id="cb16-17"><a href="bayesian.html#cb16-17"></a>df &lt;-<span class="st"> </span><span class="kw">rbind</span>(res1, res2, res3)</span>
<span id="cb16-18"><a href="bayesian.html#cb16-18"></a></span>
<span id="cb16-19"><a href="bayesian.html#cb16-19"></a>df <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb16-20"><a href="bayesian.html#cb16-20"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> precision, <span class="dt">y =</span> Mean)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb16-21"><a href="bayesian.html#cb16-21"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb16-22"><a href="bayesian.html#cb16-22"></a><span class="st">  </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Mean <span class="op">-</span><span class="st"> </span>SD, <span class="dt">ymax =</span> Mean <span class="op">+</span><span class="st"> </span>SD), <span class="dt">width =</span> <span class="dv">0</span>) <span class="op">+</span></span>
<span id="cb16-23"><a href="bayesian.html#cb16-23"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>parameter, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb16-24"><a href="bayesian.html#cb16-24"></a><span class="st">  </span><span class="kw">scale_x_log10</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb16-25"><a href="bayesian.html#cb16-25"></a><span class="st">  </span><span class="kw">coord_flip</span>()</span></code></pre></div>
<p><img src="10_bayesian-estimation_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>When the precision on the prior estimates of the intercept and slope is very high, the posterior point estimates reflect the choice of priors more than the data. It is interesting to note that the variance of the disturbances is very large when the precision is very high. This is likely because the Bayesian machine has to fight between the observed data and the strong prior, and the consequence of this fight is large uncertainty.</p>
<ol start="2" style="list-style-type: decimal">
<li>Proving claims about Bayes estimators; skipped</li>
</ol>
</div>
</div>
<div id="bayesian-interval-estimation-using-credible-intervals" class="section level2">
<h2><span class="header-section-number">10.4</span> Bayesian interval estimation using credible intervals</h2>
<div id="exercise-set-10-3" class="section level3">
<h3><span class="header-section-number">10.4.1</span> Exercise set 10-3</h3>
<ol style="list-style-type: decimal">
<li>Compute 95% credible intervals for all models in exercise 10-2-1.</li>
</ol>
<p>Skipped; see Edge for solution.</p>
</div>
</div>
<div id="bayesian-hypothesis-testing-using-bayes-factors" class="section level2">
<h2><span class="header-section-number">10.5</span> Bayesian ‘hypothesis testing’ using Bayes factors</h2>
<div id="exercise-set-10-4" class="section level3">
<h3><span class="header-section-number">10.5.1</span> Exercise set 10-4</h3>
<ol style="list-style-type: decimal">
<li>Skipped; not relevant to my interests.</li>
</ol>
</div>
</div>
<div id="conclusion-bayesian-vs.-frequentist-methods" class="section level2">
<h2><span class="header-section-number">10.6</span> Conclusion: Bayesian vs. frequentist methods</h2>
</div>
<div id="chapter-summary" class="section level2">
<h2><span class="header-section-number">10.7</span> Chapter summary</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="parametric.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
