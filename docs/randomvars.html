<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Properties of random variables | Notes on Statistical Thinking from Scratch</title>
  <meta name="description" content="Cliff notes for Statistical Thinking from Scratch, by Doc Edge." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Properties of random variables | Notes on Statistical Thinking from Scratch" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Cliff notes for Statistical Thinking from Scratch, by Doc Edge." />
  <meta name="github-repo" content="elahi/stats_from_scratch_edge" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Properties of random variables | Notes on Statistical Thinking from Scratch" />
  
  <meta name="twitter:description" content="Cliff notes for Statistical Thinking from Scratch, by Doc Edge." />
  

<meta name="author" content="Robin Elahi" />


<meta name="date" content="2020-06-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="probability.html"/>
<link rel="next" href="estimators.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-121894527-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-121894527-4');
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notes on Statistical Thinking from Scratch</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="r-eda.html"><a href="r-eda.html"><i class="fa fa-check"></i><b>2</b> R and exploratory data analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="r-eda.html"><a href="r-eda.html#inspecting-the-dataframe"><i class="fa fa-check"></i><b>2.1</b> Inspecting the dataframe</a></li>
<li class="chapter" data-level="2.2" data-path="r-eda.html"><a href="r-eda.html#histograms"><i class="fa fa-check"></i><b>2.2</b> Histograms</a></li>
<li class="chapter" data-level="2.3" data-path="r-eda.html"><a href="r-eda.html#summarising-data"><i class="fa fa-check"></i><b>2.3</b> Summarising data</a></li>
<li class="chapter" data-level="2.4" data-path="r-eda.html"><a href="r-eda.html#loops"><i class="fa fa-check"></i><b>2.4</b> Loops</a></li>
<li class="chapter" data-level="2.5" data-path="r-eda.html"><a href="r-eda.html#functions"><i class="fa fa-check"></i><b>2.5</b> Functions</a></li>
<li class="chapter" data-level="2.6" data-path="r-eda.html"><a href="r-eda.html#boxplots"><i class="fa fa-check"></i><b>2.6</b> Boxplots</a></li>
<li class="chapter" data-level="2.7" data-path="r-eda.html"><a href="r-eda.html#scatterplots"><i class="fa fa-check"></i><b>2.7</b> Scatterplots</a></li>
<li class="chapter" data-level="2.8" data-path="r-eda.html"><a href="r-eda.html#exercise-set-2-2"><i class="fa fa-check"></i><b>2.8</b> Exercise set 2-2</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="best-fit-line.html"><a href="best-fit-line.html"><i class="fa fa-check"></i><b>3</b> Line of best fit</a><ul>
<li class="chapter" data-level="3.1" data-path="best-fit-line.html"><a href="best-fit-line.html#exercise-set-3-1"><i class="fa fa-check"></i><b>3.1</b> Exercise set 3-1</a></li>
<li class="chapter" data-level="3.2" data-path="best-fit-line.html"><a href="best-fit-line.html#exercise-set-3-2"><i class="fa fa-check"></i><b>3.2</b> Exercise set 3-2</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>4</b> Probability and random variables</a><ul>
<li class="chapter" data-level="4.0.1" data-path="probability.html"><a href="probability.html#probability-vs-estimation"><i class="fa fa-check"></i><b>4.0.1</b> Probability vs estimation</a></li>
<li class="chapter" data-level="4.0.2" data-path="probability.html"><a href="probability.html#what-is-a-probability"><i class="fa fa-check"></i><b>4.0.2</b> What is a probability?</a></li>
<li class="chapter" data-level="4.0.3" data-path="probability.html"><a href="probability.html#set-notation"><i class="fa fa-check"></i><b>4.0.3</b> Set notation</a></li>
<li class="chapter" data-level="4.1" data-path="probability.html"><a href="probability.html#kolmogorovs-three-axioms-of-probability"><i class="fa fa-check"></i><b>4.1</b> Kolmogorov’s three axioms of probability</a><ul>
<li class="chapter" data-level="4.1.1" data-path="probability.html"><a href="probability.html#exercise-set-4-1"><i class="fa fa-check"></i><b>4.1.1</b> Exercise set 4-1</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="probability.html"><a href="probability.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>4.2</b> Conditional probability and independence</a><ul>
<li class="chapter" data-level="4.2.1" data-path="probability.html"><a href="probability.html#exercise-set-4-2"><i class="fa fa-check"></i><b>4.2.1</b> Exercise set 4-2</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="probability.html"><a href="probability.html#bayes-theorem"><i class="fa fa-check"></i><b>4.3</b> Bayes’ Theorem</a></li>
<li class="chapter" data-level="4.4" data-path="probability.html"><a href="probability.html#discrete-random-variables-and-distributions"><i class="fa fa-check"></i><b>4.4</b> Discrete random variables and distributions</a><ul>
<li class="chapter" data-level="4.4.1" data-path="probability.html"><a href="probability.html#exercise-set-4-3"><i class="fa fa-check"></i><b>4.4.1</b> Exercise set 4-3</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="probability.html"><a href="probability.html#continuous-random-variables-and-distributions"><i class="fa fa-check"></i><b>4.5</b> Continuous random variables and distributions</a><ul>
<li class="chapter" data-level="4.5.1" data-path="probability.html"><a href="probability.html#exercise-set-4-4"><i class="fa fa-check"></i><b>4.5.1</b> Exercise set 4-4</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="probability.html"><a href="probability.html#probability-density-functions"><i class="fa fa-check"></i><b>4.6</b> Probability density functions</a><ul>
<li class="chapter" data-level="4.6.1" data-path="probability.html"><a href="probability.html#additional-viz"><i class="fa fa-check"></i><b>4.6.1</b> Additional viz</a></li>
<li class="chapter" data-level="4.6.2" data-path="probability.html"><a href="probability.html#exercise-set-4-5"><i class="fa fa-check"></i><b>4.6.2</b> Exercise set 4-5</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="probability.html"><a href="probability.html#families-of-distributions"><i class="fa fa-check"></i><b>4.7</b> Families of distributions</a><ul>
<li class="chapter" data-level="4.7.1" data-path="probability.html"><a href="probability.html#exercise-set-4-6"><i class="fa fa-check"></i><b>4.7.1</b> Exercise set 4-6</a></li>
<li class="chapter" data-level="4.7.2" data-path="probability.html"><a href="probability.html#additional-exercise"><i class="fa fa-check"></i><b>4.7.2</b> Additional exercise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="randomvars.html"><a href="randomvars.html"><i class="fa fa-check"></i><b>5</b> Properties of random variables</a><ul>
<li class="chapter" data-level="5.1" data-path="randomvars.html"><a href="randomvars.html#expected-values-and-the-law-of-large-numbers"><i class="fa fa-check"></i><b>5.1</b> Expected values and the law of large numbers</a><ul>
<li class="chapter" data-level="5.1.1" data-path="randomvars.html"><a href="randomvars.html#weak-law-of-large-numbers"><i class="fa fa-check"></i><b>5.1.1</b> Weak law of large numbers</a></li>
<li class="chapter" data-level="5.1.2" data-path="randomvars.html"><a href="randomvars.html#handy-facts-about-expectations"><i class="fa fa-check"></i><b>5.1.2</b> Handy facts about expectations</a></li>
<li class="chapter" data-level="5.1.3" data-path="randomvars.html"><a href="randomvars.html#exercise-set-5-1"><i class="fa fa-check"></i><b>5.1.3</b> Exercise set 5-1</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="randomvars.html"><a href="randomvars.html#variance-and-standard-deviation"><i class="fa fa-check"></i><b>5.2</b> Variance and standard deviation</a><ul>
<li class="chapter" data-level="5.2.1" data-path="randomvars.html"><a href="randomvars.html#beautiful-properties-of-the-variance"><i class="fa fa-check"></i><b>5.2.1</b> Beautiful properties of the variance</a></li>
<li class="chapter" data-level="5.2.2" data-path="randomvars.html"><a href="randomvars.html#exercise-set-5-2"><i class="fa fa-check"></i><b>5.2.2</b> Exercise set 5-2</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="randomvars.html"><a href="randomvars.html#joint-distributions-covariance-and-correlation"><i class="fa fa-check"></i><b>5.3</b> Joint distributions, covariance, and correlation</a><ul>
<li class="chapter" data-level="5.3.1" data-path="randomvars.html"><a href="randomvars.html#joint-probability-distributions"><i class="fa fa-check"></i><b>5.3.1</b> Joint probability distributions</a></li>
<li class="chapter" data-level="5.3.2" data-path="randomvars.html"><a href="randomvars.html#marginal-distributions"><i class="fa fa-check"></i><b>5.3.2</b> Marginal distributions</a></li>
<li class="chapter" data-level="5.3.3" data-path="randomvars.html"><a href="randomvars.html#covariance"><i class="fa fa-check"></i><b>5.3.3</b> Covariance</a></li>
<li class="chapter" data-level="5.3.4" data-path="randomvars.html"><a href="randomvars.html#correlation"><i class="fa fa-check"></i><b>5.3.4</b> Correlation</a></li>
<li class="chapter" data-level="5.3.5" data-path="randomvars.html"><a href="randomvars.html#additional-exercise-1"><i class="fa fa-check"></i><b>5.3.5</b> Additional exercise</a></li>
<li class="chapter" data-level="5.3.6" data-path="randomvars.html"><a href="randomvars.html#exercise-set-5-3"><i class="fa fa-check"></i><b>5.3.6</b> Exercise set 5-3</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="randomvars.html"><a href="randomvars.html#conditional-distribution-expectation-variance"><i class="fa fa-check"></i><b>5.4</b> Conditional distribution, expectation, variance</a></li>
<li class="chapter" data-level="5.5" data-path="randomvars.html"><a href="randomvars.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>5.5</b> The central limit theorem</a><ul>
<li class="chapter" data-level="5.5.1" data-path="randomvars.html"><a href="randomvars.html#exercise-set-5-4"><i class="fa fa-check"></i><b>5.5.1</b> Exercise set 5-4</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="randomvars.html"><a href="randomvars.html#a-probabilistic-model-for-simple-linear-regression"><i class="fa fa-check"></i><b>5.6</b> A probabilistic model for simple linear regression</a><ul>
<li class="chapter" data-level="5.6.1" data-path="randomvars.html"><a href="randomvars.html#assumptions-of-the-linear-model"><i class="fa fa-check"></i><b>5.6.1</b> Assumptions of the linear model</a></li>
<li class="chapter" data-level="5.6.2" data-path="randomvars.html"><a href="randomvars.html#important-claims-that-follow-from-these-assumptions"><i class="fa fa-check"></i><b>5.6.2</b> Important claims that follow from these assumptions</a></li>
<li class="chapter" data-level="5.6.3" data-path="randomvars.html"><a href="randomvars.html#checking-these-assumptions"><i class="fa fa-check"></i><b>5.6.3</b> Checking these assumptions</a></li>
<li class="chapter" data-level="5.6.4" data-path="randomvars.html"><a href="randomvars.html#exercise-set-5-5"><i class="fa fa-check"></i><b>5.6.4</b> Exercise set 5-5</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="estimators.html"><a href="estimators.html"><i class="fa fa-check"></i><b>6</b> Properties of point estimators</a><ul>
<li class="chapter" data-level="6.1" data-path="estimators.html"><a href="estimators.html#bias"><i class="fa fa-check"></i><b>6.1</b> Bias</a><ul>
<li class="chapter" data-level="6.1.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-1"><i class="fa fa-check"></i><b>6.1.1</b> Exercise set 6-1</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="estimators.html"><a href="estimators.html#variance"><i class="fa fa-check"></i><b>6.2</b> Variance</a><ul>
<li class="chapter" data-level="6.2.1" data-path="estimators.html"><a href="estimators.html#exercise-set-6-2"><i class="fa fa-check"></i><b>6.2.1</b> Exercise set 6-2</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes on Statistical Thinking from Scratch</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="randomvars" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Properties of random variables</h1>
<div id="expected-values-and-the-law-of-large-numbers" class="section level2">
<h2><span class="header-section-number">5.1</span> Expected values and the law of large numbers</h2>
<p>When summarizing a probability distribution, it is useful to have a measure of:</p>
<ul>
<li>Location (<em>Expectation</em>; E(<span class="math inline">\(X\)</span>))</li>
<li>Dispersal (<em>Variance</em>; Var(<span class="math inline">\(X\)</span>))</li>
</ul>
<p>In this section, we’re focusing on the expectation.</p>
<p>The expectation of a discrete random variable is the average:</p>
<p><span class="math display">\[
\begin{aligned}
\text{E}(X) =&amp; \sum_{i = 1}^{k}x_i P(X = x_i) \\
=&amp; \sum_{i = 1}^{k}x_i f_X(x_i) \\
\end{aligned}
\]</span></p>
<p>If <span class="math inline">\(Y\)</span> represents a six-sided die, then:</p>
<p><span class="math display">\[
\begin{aligned}
\text{E}(Y) =&amp; \sum_{i = 1}^{k}y_i f_Y(y_i) \\
=&amp; 1(1/6) + 2(1/6) + 3(1/6) + 4(1/6) + 5(1/6) + 6(1/6) \\
=&amp; 21/6 \\ 
=&amp; 7/2 \\
\end{aligned}
\]</span></p>
<p>If <span class="math inline">\(X\)</span> is continuous:</p>
<p><span class="math display">\[
\begin{aligned}
\text{E}(X) =&amp; \int_{- \infty}^{\infty} x f_X(x) dx \\
\end{aligned}
\]</span></p>
<p>Here we are integrating over the probability density function, rather than summing over the mass density function.</p>
<div id="weak-law-of-large-numbers" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Weak law of large numbers</h3>
<p>The expectation is more like a long-term average, rather than an actual instance (7/2 is not a possible instance of a dice roll).</p>
<p><span class="math inline">\(X_i\)</span> are i.i.d.</p>
<p>Assume E(<span class="math inline">\(X_1\)</span>) = E(<span class="math inline">\(X_2\)</span>) = … = E(<span class="math inline">\(X_n\)</span>) = <span class="math inline">\(\mu\)</span></p>
<p>Define <span class="math inline">\(\overline{X}_n\)</span> as the mean of the observations:</p>
<p><span class="math display">\[
\begin{aligned}
\overline{X}_n = \frac{1}{n} (X_1 + X_2 + X_3 + ... + X_n)
\end{aligned}
\]</span></p>
<p>As <span class="math inline">\(n \rightarrow \infty\)</span>, <span class="math inline">\(\overline{X}_n\)</span> “converges in probability” to <span class="math inline">\(\mu\)</span>. This means for any positive constant <span class="math inline">\(\delta\)</span>,</p>
<p><span class="math display">\[
\begin{aligned}
lim_{n \rightarrow \infty} \text{P}(|\overline{X}_n - \mu| &gt; \delta) = 0
\end{aligned}
\]</span></p>
</div>
<div id="handy-facts-about-expectations" class="section level3">
<h3><span class="header-section-number">5.1.2</span> Handy facts about expectations</h3>
<p>The expectation of a constant times a random variable is the constant times the expectation of the random variable:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}(aX) = a \text{E}(X)
\end{aligned}
\]</span>
The expectation of a constant is the constant:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}(c) = c
\end{aligned}
\]</span></p>
<p>The expectation of a sum of random variables is the sum of the expectations of those random variables:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}(X + Y) = \text{E}(X) + \text{E}(Y)
\end{aligned}
\]</span></p>
<p>Putting all these facts together, we can calculate the expectation of two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> as:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}(aX + bY + c) = a \text{E}(X) + b \text{E}(Y) + c
\end{aligned}
\]</span></p>
<p>This is called the <strong>linearity of expectation</strong>, which we will use frequently in the exercises. Linearity does not hold for other measures of location (e.g., median, mode). This fact accounts, in part, for the privileged status of the mean in statistics.</p>
<p>To calculate the expectation of a function:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}[g(X)] = \sum_{i = 1}^{k} g(x_i)f_X(x_i)
\end{aligned}
\]</span></p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}[g(X)] = \int_{-\infty}^{\infty} g(x)f_X(x)dx
\end{aligned}
\]</span></p>
</div>
<div id="exercise-set-5-1" class="section level3">
<h3><span class="header-section-number">5.1.3</span> Exercise set 5-1</h3>
<p>1a. Expected value of a Bernoulli random variable with parameter <em>p</em>?</p>
<p><span class="math display">\[ 
\begin{aligned}
f_X(x) = \text{P}(X = x) = p^x(1 - p)^{1-x} \text{ for } x \in \text{{0, 1}} \\
\end{aligned}
\]</span></p>
<p>Because there are only two outcomes (0 or 1), we can compute the expectation directly:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}(X) =&amp; \sum_0^1 x f_X(x) \\
=&amp; \sum_0^1 x p^x(1 - p)^{1-x} \\ 
=&amp; 0 p^0(1 - p)^{1-0} + 1 p^1(1 - p)^{1-1} \\
=&amp; 0 p^0(1 - p)^{1} + 1 p^1(1 - p)^{0} \\
=&amp; 0 (1) (1-p) + p(1) \\ 
=&amp; 0 + p \\
=&amp; p
\end{aligned}
\]</span></p>
<p>1b. What is the expected value of a binomial random variable with parameters <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>?</p>
<p>Here’s the pmf for the binomial distribution:</p>
<p><span class="math display">\[ 
\begin{aligned}
f_X(x) = \text{P}(X = x) = \binom{n}{x} p^x(1 - p)^{n - x} \text{ for } x \in \text{{0, 1, 2, ..., n}} \\
\end{aligned}
\]</span></p>
<p>If we plug that into the equation for E(<span class="math inline">\(X\)</span>), we get:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}(X) =&amp; \sum_0^n x f_X(x) \\
=&amp; \sum_0^n x \binom{n}{x} p^x(1 - p)^{n - x} \\ 
\end{aligned}
\]</span>
Well, I don’t know how to evaluate this sum directly, considering the upper limit of <span class="math inline">\(n\)</span> is infinite. So we’ll use the fact that the binomial is the sum of <span class="math inline">\(n\)</span> independent Bernoulli trials (<span class="math inline">\(X_i\)</span>).</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}(X) =&amp; \text{E}(\sum_{i=1}^nX_i)
\end{aligned}
\]</span></p>
<p>Because the expectation is linear, the expectation of the sum is the sum of the expectations; we can rearrange:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}(X) =&amp; \sum_{i=1}^n \text{E}(X_i)
\end{aligned}
\]</span></p>
<p>From 1a, we can substitute <span class="math inline">\(p\)</span> for <span class="math inline">\(\text{E}(X_i)\)</span>:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}(X) =&amp; \sum_{i=1}^n p \\
=&amp; np
\end{aligned}
\]</span></p>
<p>1c. What is the expected value of a discrete uniform random variable with parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>?</p>
<p>The probability mass function is:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{P}(X = k) =&amp; \frac{1}{b - a + 1} \\
\end{aligned}
\]</span>
The expectation is:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}(X) =&amp; \sum_{x = a}^b x f_X(x) \\
=&amp; \sum_{x = a}^b x \frac{1}{b - a + 1}  \\
=&amp; \frac{1}{b - a + 1} \sum_{x = a}^b x \\
\end{aligned}
\]</span></p>
<p>We were given a hint that is useful now: for integers <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> with <span class="math inline">\(b &gt; a\)</span>, the sum of all the integers including <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, is:</p>
<p><span class="math display">\[ 
\begin{aligned}
\sum_{k = a}^b k  =&amp; \frac{(a + b)(b - a + 1)}{2} \\
\end{aligned}
\]</span></p>
<p>So, plugging that hint in we get:</p>
<p><span class="math display">\[ 
\begin{aligned}
=&amp; \frac{1}{b - a + 1} \times \frac{(a + b)(b - a + 1)}{2} \\
=&amp; \frac{a + b}{2} \\
\end{aligned}
\]</span></p>
<p>1d. What is the expected value of a continuous uniform random variable with parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>?</p>
<p>The probability density function is:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{P}(X) =&amp; \frac{1}{b - a} \\
\end{aligned}
\]</span></p>
<p>The expectation is:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}(X) =&amp; \int_{a}^b x f_X(x) dx \\
=&amp; \int_{a}^b x \frac{1}{b - a} dx  \\
=&amp; \frac{1}{b - a} \int_{a}^b x  dx  \\
\end{aligned}
\]</span></p>
<p>Now we have to integrate the 2nd term:</p>
<p><span class="math display">\[ 
\begin{aligned}
=&amp; \frac{1}{b - a} \times \frac{1}{2} x^2 \bigg\rvert_{a}^{b} \\
=&amp; \frac{1}{b - a} \times (\frac{b^2}{2} - \frac{a^2}{2}) \\
=&amp; \frac{1}{b - a} \times (\frac{b^2 - a^2}{2}) \\
\end{aligned}
\]</span></p>
<p>We use the hint from earlier, that <span class="math inline">\(b^2 - a^2 = (b-a)(b+a)\)</span>:</p>
<p><span class="math display">\[ 
\begin{aligned}
=&amp; \frac{1}{b - a} \times (\frac{(b-a)(b+a)}{2}) \\
=&amp; \frac{a + b}{2} \\
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Exploring the law of large numbers by simulation. In Edge’s code block below, <code>samp.size</code> represents <span class="math inline">\(n\)</span> in the weak law of large numbers (above); <code>n.samps</code> represents independent random variables <span class="math inline">\(X_n\)</span>. The expectation for all <span class="math inline">\(X_i\)</span> is <span class="math inline">\(\mu\)</span>.</li>
</ol>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" title="1">samp.size &lt;-<span class="st"> </span><span class="dv">20</span></a>
<a class="sourceLine" id="cb78-2" title="2">n.samps &lt;-<span class="st"> </span><span class="dv">1000</span></a>
<a class="sourceLine" id="cb78-3" title="3">samps &lt;-<span class="st"> </span><span class="kw">rnorm</span>(samp.size <span class="op">*</span><span class="st"> </span>n.samps, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb78-4" title="4"><span class="co"># Each column represents a random variable, X_i</span></a>
<a class="sourceLine" id="cb78-5" title="5"><span class="co"># Each row represents a sample (instance) drawn from X_i</span></a>
<a class="sourceLine" id="cb78-6" title="6">samp.mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(samps, <span class="dt">ncol =</span> n.samps) </a>
<a class="sourceLine" id="cb78-7" title="7"><span class="kw">str</span>(samp.mat)</a></code></pre></div>
<pre><code>##  num [1:20, 1:1000] 1.5807 1.7095 0.0137 0.0214 -1.0792 ...</code></pre>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" title="1"><span class="co"># Here we calculate the sample mean for each X_i (column)</span></a>
<a class="sourceLine" id="cb80-2" title="2">samp.means &lt;-<span class="st"> </span><span class="kw">colMeans</span>(samp.mat)</a>
<a class="sourceLine" id="cb80-3" title="3"><span class="kw">str</span>(samp.means)</a></code></pre></div>
<pre><code>##  num [1:1000] -0.3008 0.0284 -0.3274 -0.3161 0.3096 ...</code></pre>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" title="1"><span class="kw">hist</span>(samp.means)</a></code></pre></div>
<p><img src="05_random-variables_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>2a. What happens if we change <code>samp.size</code> (i.e., <span class="math inline">\(n\)</span>)?</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb83-1" title="1">n_vector &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb83-2" title="2">samp_means_mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">data =</span> <span class="ot">NA</span>, <span class="dt">nrow =</span> n.samps, <span class="dt">ncol =</span> <span class="kw">length</span>(n_vector))</a>
<a class="sourceLine" id="cb83-3" title="3"></a>
<a class="sourceLine" id="cb83-4" title="4">calculate_sample_means &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">samp.size =</span> <span class="dv">20</span>, <span class="dt">n.samps =</span> <span class="dv">1000</span>){</a>
<a class="sourceLine" id="cb83-5" title="5">  samps &lt;-<span class="st"> </span><span class="kw">rnorm</span>(samp.size <span class="op">*</span><span class="st"> </span>n.samps, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb83-6" title="6">  samp.mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(samps, <span class="dt">ncol =</span> n.samps) </a>
<a class="sourceLine" id="cb83-7" title="7">  samp.means &lt;-<span class="st"> </span><span class="kw">colMeans</span>(samp.mat)</a>
<a class="sourceLine" id="cb83-8" title="8">  <span class="kw">return</span>(samp.means)</a>
<a class="sourceLine" id="cb83-9" title="9">}</a>
<a class="sourceLine" id="cb83-10" title="10"></a>
<a class="sourceLine" id="cb83-11" title="11"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))</a>
<a class="sourceLine" id="cb83-12" title="12"><span class="kw">set.seed</span>(<span class="dv">21</span>)</a>
<a class="sourceLine" id="cb83-13" title="13"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(n_vector)){</a>
<a class="sourceLine" id="cb83-14" title="14">  samp_size_i &lt;-<span class="st"> </span>n_vector[i]</a>
<a class="sourceLine" id="cb83-15" title="15">  samp_means_i &lt;-<span class="st"> </span><span class="kw">calculate_sample_means</span>(<span class="dt">samp.size =</span> samp_size_i)</a>
<a class="sourceLine" id="cb83-16" title="16">  <span class="kw">hist</span>(samp_means_i, <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">250</span>), </a>
<a class="sourceLine" id="cb83-17" title="17">       <span class="dt">xlab =</span> <span class="st">&quot;Sample mean&quot;</span>, </a>
<a class="sourceLine" id="cb83-18" title="18">       <span class="dt">main =</span> <span class="kw">paste</span>(<span class="st">&quot;n = &quot;</span>, samp_size_i, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb83-19" title="19">}</a></code></pre></div>
<p><img src="05_random-variables_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>2b. Using the exponential distribution.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" title="1">n_vector &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb84-2" title="2">samp_means_mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">data =</span> <span class="ot">NA</span>, <span class="dt">nrow =</span> n.samps, <span class="dt">ncol =</span> <span class="kw">length</span>(n_vector))</a>
<a class="sourceLine" id="cb84-3" title="3"></a>
<a class="sourceLine" id="cb84-4" title="4">calculate_sample_means_exp &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">samp.size =</span> <span class="dv">20</span>, <span class="dt">n.samps =</span> <span class="dv">1000</span>){</a>
<a class="sourceLine" id="cb84-5" title="5">  samps &lt;-<span class="st"> </span><span class="kw">rexp</span>(samp.size <span class="op">*</span><span class="st"> </span>n.samps, <span class="dt">rate =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb84-6" title="6">  samp.mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(samps, <span class="dt">ncol =</span> n.samps) </a>
<a class="sourceLine" id="cb84-7" title="7">  samp.means &lt;-<span class="st"> </span><span class="kw">colMeans</span>(samp.mat)</a>
<a class="sourceLine" id="cb84-8" title="8">  <span class="kw">return</span>(samp.means)</a>
<a class="sourceLine" id="cb84-9" title="9">}</a>
<a class="sourceLine" id="cb84-10" title="10"></a>
<a class="sourceLine" id="cb84-11" title="11"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))</a>
<a class="sourceLine" id="cb84-12" title="12"><span class="kw">set.seed</span>(<span class="dv">21</span>)</a>
<a class="sourceLine" id="cb84-13" title="13"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(n_vector)){</a>
<a class="sourceLine" id="cb84-14" title="14">  samp_size_i &lt;-<span class="st"> </span>n_vector[i]</a>
<a class="sourceLine" id="cb84-15" title="15">  samp_means_i &lt;-<span class="st"> </span><span class="kw">calculate_sample_means_exp</span>(<span class="dt">samp.size =</span> samp_size_i)</a>
<a class="sourceLine" id="cb84-16" title="16">  <span class="kw">hist</span>(samp_means_i, </a>
<a class="sourceLine" id="cb84-17" title="17">       <span class="dt">xlab =</span> <span class="st">&quot;Sample mean&quot;</span>, </a>
<a class="sourceLine" id="cb84-18" title="18">       <span class="dt">main =</span> <span class="kw">paste</span>(<span class="st">&quot;n = &quot;</span>, samp_size_i, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb84-19" title="19">}</a></code></pre></div>
<p><img src="05_random-variables_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
</div>
<div id="variance-and-standard-deviation" class="section level2">
<h2><span class="header-section-number">5.2</span> Variance and standard deviation</h2>
<p>The variance is a measurement of dispersal - i.e., how spread out is the distribution? And spread out from what, exactly? It is useful to think about the distance <span class="math inline">\(X_i\)</span> takes from the expectation, E<span class="math inline">\((X)\)</span>: <span class="math inline">\(X - \text{E}(X)\)</span>. What if we took the expectation of this - i.e., the average value of the distance from the mean?</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{E}(X - \text{E}(X)) \\
\text{by linearity of expectation, we get:} \\
\text{E}(X) - \text{E}(\text{E}(X)) \\
\text{E}(X) - \text{E}(X) \\
0
\end{aligned}
\]</span></p>
<p>This won’t work - we need to find a way to constrain the expression inside the parentheses to be non-negative. One way to do this is to use the mean absolute deviation, <span class="math inline">\(|X - \text{E}(X)|\)</span>. Another way is to use the mean squared deviation, <span class="math inline">\([X - \text{E}(X)]^2\)</span>. The squared term constrains the variance to be <span class="math inline">\(\ge 0\)</span>:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{Var}(X) =&amp; \text{E}([X - \text{E}(X)]^2) \\
\end{aligned}
\]</span></p>
<p>The mean squared deviation has two mathematical advantages:</p>
<ol style="list-style-type: decimal">
<li><p>It is easier to compute mathematically than an analogous quanitity using absolute deviations (but why?)</p></li>
<li><p>The variances of linear functions of random variables are ‘beautifully behaved’, whereas the analogous quantities for absolute deviations can be a hassle.</p></li>
</ol>
<p>I will just take Edge’s word on these two points for now.</p>
<div id="beautiful-properties-of-the-variance" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Beautiful properties of the variance</h3>
<p>The variance can be rewritten as:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{Var}(X) = \text{E}(X^2) - [\text{E}(X)]^2 \\
\end{aligned}
\]</span></p>
<p>which is generally easier to compute.</p>
<p>Adding a constant to a random variable does <em>not</em> affect the variance:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{Var}(a + cX) = c^2\text{Var}(X) \\
\end{aligned}
\]</span>
where <span class="math inline">\(a\)</span> and <span class="math inline">\(c\)</span> are constants.</p>
<p>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent random variables, then:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y) \\
\end{aligned}
\]</span></p>
<p>One big problem with the variance is that is in the wrong (<span class="math inline">\(X^2\)</span>) units. To fix this, we calculate the <em>standard deviation</em>:</p>
<p><span class="math display">\[ 
\begin{aligned}
\text{SD}(X) = \sqrt{\text{Var}(X)} \\
\end{aligned}
\]</span></p>
<p>SD is usually larger (never smaller) than MAD, and is more sensitive to large deviations.</p>
</div>
<div id="exercise-set-5-2" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Exercise set 5-2</h3>
<p>I had to walk through Edge’s solutions bit by bit; my handwritten version is <a href="images/edge_4_1_3.pdf">here</a>.</p>
</div>
</div>
<div id="joint-distributions-covariance-and-correlation" class="section level2">
<h2><span class="header-section-number">5.3</span> Joint distributions, covariance, and correlation</h2>
<p>This section covers four key concepts:</p>
<ol style="list-style-type: decimal">
<li><p>Joint probability distribution: the probability distribution of the joint occurrence of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span></p></li>
<li><p>Marginal distribution of X: the probability distribution of <span class="math inline">\(X\)</span>, summing (integrating) over all values of <span class="math inline">\(Y\)</span></p></li>
<li><p>Covariance: a measurement of the extent to which <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> depart from independence</p></li>
<li><p>Correlation: covariance rescaled to go from -1 to 1</p></li>
</ol>
<div id="joint-probability-distributions" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Joint probability distributions</h3>
<p>Joint probability distribution: the probability distribution of the joint occurrence of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span></p>
<p>The joint cumulative probability distribution of two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is given by:</p>
<p><span class="math display">\[
\begin{aligned}
F_{X,Y}(x, y) = \text{P} (X \leq x ~\cap ~ Y \leq y)
\end{aligned}
\]</span></p>
<p>Here is the corresponding joint probability mass function:</p>
<p><span class="math display">\[
\begin{aligned}
f_{X,Y}(x, y) = \text{P} (X = x ~\cap ~ Y = y)
\end{aligned}
\]</span></p>
<p>And for two continuous variables, we can recover the cumulative distribution function by integrating the probability density function with respect to <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
F_{X,Y}(x, y) =&amp; ~ \text{P}(X \leq x ~\cap ~ Y \leq y) \\
=&amp; \int_{- \infty}^{x} \int_{- \infty}^{y} f_{X,Y}(x, y) dx dy
\end{aligned}
\]</span></p>
</div>
<div id="marginal-distributions" class="section level3">
<h3><span class="header-section-number">5.3.2</span> Marginal distributions</h3>
<p>Marginal distribution of X: the probability distribution of <span class="math inline">\(X\)</span>, summing (integrating) over all values of <span class="math inline">\(Y\)</span></p>
<p>For discrete random variables, the marginal distribution of <span class="math inline">\(X\)</span> is:</p>
<p><span class="math display">\[
\begin{aligned}
f_{X}(x) =&amp; ~ \text{P} (X = x) \\
         =&amp; ~ \sum_{y} \text{P} (X = x ~\cap ~ Y = y) \\
         =&amp; \sum_{y} f_{X,Y}(x,y)
\end{aligned}
\]</span></p>
<p>For continuous random variables, the marginal distribution of <span class="math inline">\(X\)</span> is:</p>
<p><span class="math display">\[
\begin{aligned}
f_{X}(x) =&amp; \int_{- \infty}^{\infty} f_{X,Y}(x, y) dy
\end{aligned}
\]</span></p>
</div>
<div id="covariance" class="section level3">
<h3><span class="header-section-number">5.3.3</span> Covariance</h3>
<p>Covariance is a measurement of the extent to which <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> depart from independence</p>
<p>Such a measure should have two basic properties:</p>
<ul>
<li>The number should be positive when <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> increase or decrease together</li>
<li>The number should be negative when <span class="math inline">\(X\)</span> increases and <span class="math inline">\(Y\)</span> decreases (and vice versa).</li>
</ul>
<p>Consider the random variable <span class="math inline">\([X - \text{E}(X)][Y - \text{E}(Y)]\)</span>. If we sample a joint probability distribution, resulting in a set (<span class="math inline">\(\Omega\)</span>) of pairs of <span class="math inline">\((x, y)\)</span>, ask yourself:</p>
<ul>
<li>Is the sign positive or negative when most of the pairs <span class="math inline">\((x, y)\)</span> are such that <span class="math inline">\(x &gt; \text{E}(X)\)</span> and <span class="math inline">\(y &gt; \text{E}(Y)\)</span>?</li>
<li>Is the sign positive or negative when most of the pairs <span class="math inline">\((x, y)\)</span> are such that <span class="math inline">\(x &lt; \text{E}(X)\)</span> and <span class="math inline">\(y &lt; \text{E}(Y)\)</span>?</li>
<li>Is the sign positive or negative when most of the pairs <span class="math inline">\((x, y)\)</span> are such that <span class="math inline">\(x &gt; \text{E}(X)\)</span> and <span class="math inline">\(y &lt; \text{E}(Y)\)</span>?</li>
<li>Is the sign positive or negative when most of the pairs <span class="math inline">\((x, y)\)</span> are such that <span class="math inline">\(x &lt; \text{E}(X)\)</span> and <span class="math inline">\(y &gt; \text{E}(Y)\)</span>?</li>
</ul>
<p>Hopefully, you have convinced yourself that the random variable <span class="math inline">\([X - \text{E}(X)][Y - \text{E}(Y)]\)</span> satisfies the two aforementioned properties. Now we take the expectation of this random variable to arrive at the covariance.</p>
<p>Conveniently (or purposefully?), the covariance is an extension of the variance:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Cov}(X,Y) =&amp; ~ \text{E}([X - \text{E}(X)][Y - \text{E}(Y)]) \\
                =&amp; ~ \text{E}(XY) - \text{E}(X)\text{E}(Y)
\end{aligned}
\]</span></p>
<p>If you replace <span class="math inline">\(\text{E}(Y)\)</span> with <span class="math inline">\(\text{E}(X)\)</span> in the above equation, you should recover the definition of Var<span class="math inline">\((X)\)</span>, <span class="math inline">\(\text{E}(X^2) - [\text{E}(X)]^2\)</span>.</p>
<p>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent, then <span class="math inline">\(\text{Cov}(X,Y) = 0\)</span> (we showed this in an earlier problem set).</p>
<p>However, if <span class="math inline">\(\text{Cov}(X,Y) = 0\)</span>, that does not necessarily imply that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent.</p>
</div>
<div id="correlation" class="section level3">
<h3><span class="header-section-number">5.3.4</span> Correlation</h3>
<p>Correlation: covariance rescaled to go from -1 to 1</p>
<p>The covariance is not a pure measure of the linear dependence between two variables, because it is sensitive to the scaling of the variables. Therefore, we cannot use the covariance to compare the strengths of different bivariate relationships. In other words, we cannot use the covariance to answer the question: <em>Is the relationship between cereal yield and fertilizer consumption stronger than the relationship between career earnings and college GPA?</em>. Instead, we calculate the correlation:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Cor}(X,Y) =&amp; ~ \rho_{X,Y} \\
                =&amp; ~ \frac{\text{Cov}(X,Y)}{\sqrt{\text{Var}(X)\text{Var}(Y)}} \\
                =&amp; ~ \frac{\text{Cov}(X,Y)}{\sigma_X \sigma_Y}\\
\end{aligned}
\]</span></p>
<p>You can prove to yourself that the correlation is bounded from -1 to 1 using a simple heuristic. Which variable should be the most correlated with <span class="math inline">\(X\)</span>? Well, that would be <span class="math inline">\(X\)</span>. Plugging in <span class="math inline">\(X\)</span> for <span class="math inline">\(Y\)</span>, we get:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Cor}(X,X) =&amp; ~ \frac{\text{Cov}(X,X)}{\sigma_X \sigma_X} \\
                 =&amp; ~ \frac{\text{Var}(X)}{\text{Var}(X)} \\
                 =&amp; ~ 1
\end{aligned}
\]</span></p>
<p>Using the same logic, <span class="math inline">\(-X\)</span>, is the least correlated with <span class="math inline">\(X\)</span>. Try working through the algebra, you should get -1:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Cor}(X,-X) =&amp; ~ \frac{\text{Cov}(X,-X)}{\sqrt{\text{Var}(X)\text{Var}(-X)}} \\
                =&amp; ~ \frac{\text{E}(X \times -X) - \text{E}(X)\text{E}(-X)}{\sqrt{\text{Var}(X)\text{Var}(-X)}} \\
\end{aligned}
\]</span></p>
</div>
<div id="additional-exercise-1" class="section level3">
<h3><span class="header-section-number">5.3.5</span> Additional exercise</h3>
<p>I will add one problem, to reinforce the concepts of joint and marginal distributions, with two discrete random variables. This problem covers similar ideas to Edge’s first exercise in set 5-3.</p>
<p>You watched 100 female birds last spring, and recorded the number of offspring per bird (X; 1, 2, or 3 chicks). You also recorded the age of each mom (Y; 1, 2, or 3 years).</p>
<p>You observed:
10 1-yr olds, all with one chick.
27 2-yr olds; 13 had one chick, 12 had two chicks, and 2 had three chicks.
63 3-yr olds; 23 had one chick, 36 had two chicks, and 4 had three chicks.</p>
<p>Calculate:</p>
<ol style="list-style-type: decimal">
<li><p>The probability of observing each possible outcome (e.g., a 1-yr old bird has 1 chick; a 1-yr old bird has 2 chicks; etc.).</p></li>
<li><p>The probability of observing a 1-yr old bird; a 2-yr old bird; and a 3-yr old bird.</p></li>
<li><p>The probability of observing 1 chick per mom; 2 chicks per mom; 3 chicks per mom.</p></li>
</ol>
<p>STOP! NO PEEKING ! ANSWER IS BELOW:</p>
<p>Wait for it…</p>
<p>…wait for it …</p>
<p>…here it is: an excel (gasp!) plot!</p>
<p><img src="images/birbs_for_rmd.png" style="width:200.0%" /></p>
<p>The key here is to recognize that yellow represents the joint probabilities of X and Y; the green and blue represents the marginal probabilities of X and Y, respectively. Stare at this until it clicks. A similar principle applies to continuous distributions, but rather than summing across Y, we integrate across Y to get the marginal distribution of X.</p>
</div>
<div id="exercise-set-5-3" class="section level3">
<h3><span class="header-section-number">5.3.6</span> Exercise set 5-3</h3>
<p>I had to walk through Edge’s solutions bit by bit; my handwritten version is <a href="images/edge_5_3.pdf">here</a>.</p>
</div>
</div>
<div id="conditional-distribution-expectation-variance" class="section level2">
<h2><span class="header-section-number">5.4</span> Conditional distribution, expectation, variance</h2>
<p>For two discrete random variables, the conditional probability mass function is:</p>
<p><span class="math display">\[
\begin{aligned}
f_{X|Y}(x |Y = y) =&amp; \text{P}(X = x | Y = y) \\
                  =&amp; \frac{\text{P} (X = x ~\cap ~ Y = y)}{\text{P}(Y = y)} \\
                  =&amp; \frac{f_{X,Y}(x,y)}{f_{Y}(y)}
\end{aligned}
\]</span></p>
<p>For two continuous random variables, the conditional probability density function is defined similarly:</p>
<p><span class="math display">\[
\begin{aligned}
f_{X|Y}(x |Y = y) =&amp; \frac{f_{X,Y}(x,y)}{f_{Y}(y)}
\end{aligned}
\]</span></p>
<p>Edge has a nice visualization and explanation of conditional distribution in his Fig 5-5.</p>
</div>
<div id="the-central-limit-theorem" class="section level2">
<h2><span class="header-section-number">5.5</span> The central limit theorem</h2>
<p>Natural populations are large, so we usually gather just a sample and use that as a surrogate for the whole population. If we take <span class="math inline">\(n\)</span> samples, then another <span class="math inline">\(n\)</span> samples, and then another <span class="math inline">\(n\)</span> samples, and calculate <span class="math inline">\(\overline{X}_1\)</span>, <span class="math inline">\(\overline{X}_2\)</span>, and <span class="math inline">\(\overline{X}_3\)</span>, differences in our estimate of <span class="math inline">\(\overline{X}\)</span> are due to sampling variation. The weak law of large numbers (above) tells us that as <span class="math inline">\(n\)</span> approaches <span class="math inline">\(\infty\)</span>, our estimate of <span class="math inline">\(\overline{X}_n\)</span> approaches the true population mean, <span class="math inline">\(\mu\)</span>, and that the Var(<span class="math inline">\(\overline{X}_n\)</span>) = <span class="math inline">\(\sigma^2 / n\)</span>, approaches 0.</p>
<p>But what is the <em>shape</em> of this distribution? That is where the central limit theorem (CLT) comes in. As <span class="math inline">\(n\)</span> approaches <span class="math inline">\(\infty\)</span>, the distribution of <span class="math inline">\(\overline{X}_n\)</span> converges to a normal distribution with expectation <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2 / n\)</span>.</p>
<p>An importance consequence of the CLT is the surpising result that the distribution of sample means <span class="math inline">\(\overline{X}_n\)</span> is <em>approximately</em> normal even when the distribution of the individual observations are not normally distributed! The implications of the CLT are huge: it allows us to use the normal distribution (and the powerful set of analytical tools that depend on it) in real-world situations where the underlying data are not normally distributed, as long as we have enough samples. What is enough? A general rule of thumb is 30, but will vary with the underlying probability distribution of the population. You will explore this using simulations in the problem set below.</p>
<div id="exercise-set-5-4" class="section level3">
<h3><span class="header-section-number">5.5.1</span> Exercise set 5-4</h3>
<ol style="list-style-type: decimal">
<li>Bean machine in action!</li>
</ol>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb85-1" title="1"><span class="kw">library</span>(animation)</a>
<a class="sourceLine" id="cb85-2" title="2">nball &lt;-<span class="st"> </span><span class="dv">500</span> <span class="co">#change the number of balls</span></a>
<a class="sourceLine" id="cb85-3" title="3">nlayer &lt;-<span class="st"> </span><span class="dv">10</span> <span class="co">#change the number of rows of pegs on the board</span></a>
<a class="sourceLine" id="cb85-4" title="4">rate &lt;-<span class="st"> </span><span class="dv">10</span> <span class="co">#change the speed at which the balls fall</span></a>
<a class="sourceLine" id="cb85-5" title="5"><span class="kw">ani.options</span>(<span class="dt">nmax =</span> nball <span class="op">+</span><span class="st"> </span>nlayer <span class="op">-</span><span class="st"> </span><span class="dv">2</span>, <span class="dt">interval =</span> <span class="dv">1</span><span class="op">/</span>rate)</a>
<a class="sourceLine" id="cb85-6" title="6"><span class="kw">quincunx</span>(<span class="dt">balls =</span> nball, <span class="dt">layers =</span> nlayer)</a></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>Exploring the beta distribution</li>
</ol>
<p>To see what the beta distribution looks like for a given set of shape parameters, set the sample size to 1. For example:</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" title="1"><span class="kw">library</span>(stfspack)</a>
<a class="sourceLine" id="cb86-2" title="2"><span class="co"># dosm.beta.hist(n = 1, nsim = 10000, shape1 = 1, shape2 = 1)</span></a></code></pre></div>
<p>will give you a histogram of 10,000 observations from a beta distribution with parameters 1 and 1. If you increase the sample size, then the distribution of the sample mean gets closer to normality. Try this — starting with samples of size 1 and increasing the sample size — with the following sets of parameter values: (1, 1), (0.2, 0.2), (2, 0.5), (0.5, 2), (3, 3). Feel free to try other parameter sets — it’s fun. What do you notice?</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb87-1" title="1">sims &lt;-<span class="st"> </span><span class="dv">1000</span></a>
<a class="sourceLine" id="cb87-2" title="2">s1 &lt;-<span class="st"> </span><span class="fl">0.2</span> <span class="co"># change this</span></a>
<a class="sourceLine" id="cb87-3" title="3">s2 &lt;-<span class="st"> </span><span class="fl">0.2</span> <span class="co"># change this</span></a>
<a class="sourceLine" id="cb87-4" title="4"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))</a>
<a class="sourceLine" id="cb87-5" title="5"><span class="kw">dosm.beta.hist</span>(<span class="dt">n =</span> <span class="dv">1</span>, <span class="dt">nsim =</span> sims, <span class="dt">shape1 =</span> s1, <span class="dt">shape2 =</span> s2)</a></code></pre></div>
<pre><code>## mean of DOSM   SD of DOSM  var of DOSM 
##    0.4976551    0.4193736    0.1758742</code></pre>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb89-1" title="1"><span class="kw">dosm.beta.hist</span>(<span class="dt">n =</span> <span class="dv">4</span>, <span class="dt">nsim =</span> sims, <span class="dt">shape1 =</span> s1, <span class="dt">shape2 =</span> s2)</a></code></pre></div>
<pre><code>## mean of DOSM   SD of DOSM  var of DOSM 
##   0.51873441   0.21324943   0.04547532</code></pre>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb91-1" title="1"><span class="kw">dosm.beta.hist</span>(<span class="dt">n =</span> <span class="dv">8</span>, <span class="dt">nsim =</span> sims, <span class="dt">shape1 =</span> s1, <span class="dt">shape2 =</span> s2)</a></code></pre></div>
<pre><code>## mean of DOSM   SD of DOSM  var of DOSM 
##   0.50331631   0.14985449   0.02245637</code></pre>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb93-1" title="1"><span class="kw">dosm.beta.hist</span>(<span class="dt">n =</span> <span class="dv">16</span>, <span class="dt">nsim =</span> sims, <span class="dt">shape1 =</span> s1, <span class="dt">shape2 =</span> s2)</a></code></pre></div>
<pre><code>## mean of DOSM   SD of DOSM  var of DOSM 
##   0.49738079   0.10502289   0.01102981</code></pre>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb95-1" title="1"><span class="kw">dosm.beta.hist</span>(<span class="dt">n =</span> <span class="dv">32</span>, <span class="dt">nsim =</span> sims, <span class="dt">shape1 =</span> s1, <span class="dt">shape2 =</span> s2)</a></code></pre></div>
<pre><code>## mean of DOSM   SD of DOSM  var of DOSM 
##  0.500954728  0.075780685  0.005742712</code></pre>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb97-1" title="1"><span class="kw">dosm.beta.hist</span>(<span class="dt">n =</span> <span class="dv">64</span>, <span class="dt">nsim =</span> sims, <span class="dt">shape1 =</span> s1, <span class="dt">shape2 =</span> s2)</a></code></pre></div>
<p><img src="05_random-variables_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre><code>## mean of DOSM   SD of DOSM  var of DOSM 
##  0.500007026  0.053298265  0.002840705</code></pre>
<p>Let’s deconstruct what is going on with this function, where n = 1 (we simulate 10000 observations from a single set of parameter values).</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb99-1" title="1">dosm.beta.hist</a></code></pre></div>
<pre><code>## function (n, nsim, shape1 = 1, shape2 = 1, ...) 
## {
##     samps &lt;- rbeta(n * nsim, shape1, shape2)
##     sim.mat &lt;- matrix(samps, nrow = nsim)
##     dosm &lt;- rowMeans(sim.mat)
##     hist(dosm, freq = FALSE, ...)
##     x &lt;- seq(0, 1, length.out = 1000)
##     lines(x, dnorm(x, mean = mean(dosm), sd = sd(dosm)))
##     c(`mean of DOSM` = mean(dosm), `SD of DOSM` = sd(dosm), `var of DOSM` = var(dosm))
## }
## &lt;bytecode: 0x7f9be028a080&gt;
## &lt;environment: namespace:stfspack&gt;</code></pre>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb101-1" title="1">nsim &lt;-<span class="st"> </span><span class="dv">10000</span></a>
<a class="sourceLine" id="cb101-2" title="2">n &lt;-<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb101-3" title="3">s1 &lt;-<span class="st"> </span><span class="fl">0.2</span> <span class="co"># change this</span></a>
<a class="sourceLine" id="cb101-4" title="4">s2 &lt;-<span class="st"> </span><span class="fl">0.2</span> <span class="co"># change this</span></a>
<a class="sourceLine" id="cb101-5" title="5">samps &lt;-<span class="st"> </span><span class="kw">rbeta</span>(n <span class="op">*</span><span class="st"> </span>nsim, <span class="dt">shape1 =</span> s1, <span class="dt">shape2 =</span> s2)</a>
<a class="sourceLine" id="cb101-6" title="6"><span class="kw">str</span>(samps) <span class="co"># here are 10,000 samples</span></a></code></pre></div>
<pre><code>##  num [1:10000] 0.13472 0.70805 0.99361 0.00268 0.58459 ...</code></pre>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb103-1" title="1"><span class="co"># We are converting the vector into a matrix</span></a>
<a class="sourceLine" id="cb103-2" title="2"><span class="co"># So that we can easily calculate the mean of each row</span></a>
<a class="sourceLine" id="cb103-3" title="3">sim.mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(samps, <span class="dt">nrow =</span> nsim)</a>
<a class="sourceLine" id="cb103-4" title="4"><span class="kw">dim</span>(sim.mat); <span class="kw">head</span>(sim.mat)</a></code></pre></div>
<pre><code>## [1] 10000     1</code></pre>
<pre><code>##            [,1]
## [1,] 0.13471512
## [2,] 0.70804823
## [3,] 0.99361002
## [4,] 0.00268066
## [5,] 0.58459079
## [6,] 0.99641568</code></pre>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb106-1" title="1"><span class="co"># Calculate rowmeans - with n=1, this doesn&#39;t change anything</span></a>
<a class="sourceLine" id="cb106-2" title="2"><span class="co"># But change n to anything bigger and inspect the dimensions of the objects</span></a>
<a class="sourceLine" id="cb106-3" title="3">dosm &lt;-<span class="st"> </span><span class="kw">rowMeans</span>(sim.mat)</a>
<a class="sourceLine" id="cb106-4" title="4"><span class="kw">str</span>(dosm) <span class="co"># compare these values to sim.mat</span></a></code></pre></div>
<pre><code>##  num [1:10000] 0.13472 0.70805 0.99361 0.00268 0.58459 ...</code></pre>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb108-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</a>
<a class="sourceLine" id="cb108-2" title="2"><span class="kw">hist</span>(dosm, <span class="dt">freq =</span> <span class="ot">FALSE</span>) <span class="co"># plotting the simulated values</span></a>
<a class="sourceLine" id="cb108-3" title="3"></a>
<a class="sourceLine" id="cb108-4" title="4"><span class="co"># Set up a vector that goes from 0 to 1 to overlay a normal distribution on the histogram</span></a>
<a class="sourceLine" id="cb108-5" title="5">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> <span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb108-6" title="6"></a>
<a class="sourceLine" id="cb108-7" title="7"><span class="co"># Now plot a normal distribution, using the mean and sd of the simulated values</span></a>
<a class="sourceLine" id="cb108-8" title="8"><span class="kw">lines</span>(x, <span class="kw">dnorm</span>(x, <span class="dt">mean =</span> <span class="kw">mean</span>(dosm), <span class="dt">sd =</span> <span class="kw">sd</span>(dosm)), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<p><img src="05_random-variables_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<ol start="3" style="list-style-type: decimal">
<li>The Pareto distribution is a skewed, heavy-tailed, power-law distribution used in description of social, scientific, geophysical, actuarial, and many other types of observable phenomena. It was applied originally to the distribution of wealth in a society, fitting the observation that a large portion of wealth is held by a small fraction of the population. Named after the Italian civil engineer, economist, and sociologist Vilfredo Pareto.</li>
</ol>
<p>Parameters of the <code>rpareto</code> function:</p>
<ul>
<li>a: shape (on the web as <span class="math inline">\(\alpha\)</span>)</li>
<li>b: scale (on the web as <span class="math inline">\(x_m\)</span>)</li>
</ul>
<p>If the shape parameter is <span class="math inline">\(\leq\)</span> 1, <span class="math inline">\(E(X)\)</span> is <span class="math inline">\(\infty\)</span>.
If the shape parameter is <span class="math inline">\(\leq\)</span> 2, <span class="math inline">\(Var(X)\)</span> is <span class="math inline">\(\infty\)</span>.</p>
<p>First we simulate many sampes of size 1000 from a Pareto distribution with shape = 4.</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb109-1" title="1"><span class="co"># experiment with n and the parameters a and b</span></a>
<a class="sourceLine" id="cb109-2" title="2">n &lt;-<span class="st"> </span><span class="dv">100</span></a>
<a class="sourceLine" id="cb109-3" title="3">n_sims &lt;-<span class="st"> </span><span class="dv">10000</span></a>
<a class="sourceLine" id="cb109-4" title="4">a &lt;-<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb109-5" title="5">b &lt;-<span class="st"> </span><span class="dv">4</span></a>
<a class="sourceLine" id="cb109-6" title="6"></a>
<a class="sourceLine" id="cb109-7" title="7">x &lt;-<span class="st"> </span><span class="kw">rpareto</span>(<span class="dt">n =</span> n, <span class="dt">a =</span> a, <span class="dt">b =</span> b)</a>
<a class="sourceLine" id="cb109-8" title="8"><span class="kw">summary</span>(x)</a></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   4.076   6.120   9.899  29.924  20.622 928.145</code></pre>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb111-1" title="1"><span class="co"># Calculate mean and sd</span></a>
<a class="sourceLine" id="cb111-2" title="2">mu &lt;-<span class="st"> </span><span class="kw">mean</span>(x)</a>
<a class="sourceLine" id="cb111-3" title="3">stdev &lt;-<span class="st"> </span><span class="kw">sd</span>(x)</a>
<a class="sourceLine" id="cb111-4" title="4"></a>
<a class="sourceLine" id="cb111-5" title="5"><span class="kw">hist</span>(x, <span class="dt">freq =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb111-6" title="6"><span class="co"># Set up a vector that goes from 0 to 1 to overlay a normal distribution on the histogram</span></a>
<a class="sourceLine" id="cb111-7" title="7">x_vals &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(x), <span class="kw">max</span>(x), <span class="dt">length.out =</span> <span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb111-8" title="8"><span class="co"># Now plot a normal distribution, using the mean and sd of the simulated values</span></a>
<a class="sourceLine" id="cb111-9" title="9"><span class="kw">lines</span>(x_vals, <span class="kw">dnorm</span>(x_vals, <span class="dt">mean =</span> mu, <span class="dt">sd =</span> stdev), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<p><img src="05_random-variables_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb112-1" title="1"><span class="co"># Compare tail to normal</span></a>
<a class="sourceLine" id="cb112-2" title="2">compare.tail.to.normal</a></code></pre></div>
<pre><code>## function (x, k, mu, sigma) 
## {
##     mean(x &lt; (mu - k * sigma) | x &gt; (mu + k * sigma))/(1 - (pnorm(k) - 
##         pnorm(-k)))
## }
## &lt;bytecode: 0x7f9be02ddee0&gt;
## &lt;environment: namespace:stfspack&gt;</code></pre>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb114-1" title="1">k &lt;-<span class="st"> </span><span class="dv">2</span> <span class="co"># sds</span></a>
<a class="sourceLine" id="cb114-2" title="2"><span class="kw">compare.tail.to.normal</span>(<span class="dt">x =</span> x, <span class="dt">k =</span> k, <span class="dt">mu =</span> mu, <span class="dt">sigma =</span> stdev)</a></code></pre></div>
<pre><code>## [1] 0.2197789</code></pre>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb116-1" title="1"><span class="kw">summary</span>(x)</a></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   4.076   6.120   9.899  29.924  20.622 928.145</code></pre>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb118-1" title="1">mu</a></code></pre></div>
<pre><code>## [1] 29.92446</code></pre>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb120-1" title="1">stdev</a></code></pre></div>
<pre><code>## [1] 95.49789</code></pre>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb122-1" title="1"><span class="co"># This gives the value of the mean, minus the value k*stdev</span></a>
<a class="sourceLine" id="cb122-2" title="2"><span class="co"># (i.e., an extreme negative value)</span></a>
<a class="sourceLine" id="cb122-3" title="3"><span class="co"># Below I will use my object stdev in place of sigma (the parameter from Edge&#39;s function)</span></a>
<a class="sourceLine" id="cb122-4" title="4">(mu <span class="op">-</span><span class="st"> </span>k <span class="op">*</span><span class="st"> </span>stdev)</a></code></pre></div>
<pre><code>## [1] -161.0713</code></pre>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb124-1" title="1"><span class="co"># Extreme positive value</span></a>
<a class="sourceLine" id="cb124-2" title="2">(mu <span class="op">+</span><span class="st"> </span>k <span class="op">*</span><span class="st"> </span>stdev)</a></code></pre></div>
<pre><code>## [1] 220.9202</code></pre>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb126-1" title="1"><span class="co"># This statement asks whether the value in x is an extreme value</span></a>
<a class="sourceLine" id="cb126-2" title="2"><span class="co"># The operator &#39;|&#39; is &#39;OR&#39;</span></a>
<a class="sourceLine" id="cb126-3" title="3"><span class="co"># Is x extreme negative OR extreme positive?</span></a>
<a class="sourceLine" id="cb126-4" title="4">x <span class="op">&lt;</span><span class="st"> </span>(mu <span class="op">-</span><span class="st"> </span>k <span class="op">*</span><span class="st"> </span>stdev) <span class="op">|</span><span class="st"> </span>x <span class="op">&gt;</span><span class="st"> </span>(mu <span class="op">+</span><span class="st"> </span>k <span class="op">*</span><span class="st"> </span>stdev)</a></code></pre></div>
<pre><code>##   [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [61] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
##  [97] FALSE FALSE FALSE FALSE</code></pre>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb128-1" title="1"><span class="co"># We can get the frequencies of this logical vector using table</span></a>
<a class="sourceLine" id="cb128-2" title="2"><span class="kw">table</span>(x <span class="op">&lt;</span><span class="st"> </span>(mu <span class="op">-</span><span class="st"> </span>k <span class="op">*</span><span class="st"> </span>stdev) <span class="op">|</span><span class="st"> </span>x <span class="op">&gt;</span><span class="st"> </span>(mu <span class="op">+</span><span class="st"> </span>k <span class="op">*</span><span class="st"> </span>stdev))</a></code></pre></div>
<pre><code>## 
## FALSE  TRUE 
##    99     1</code></pre>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb130-1" title="1"><span class="co"># Or, as Edge, does, calculate the average of TRUEs - which is simply the proportion of TRUEs</span></a>
<a class="sourceLine" id="cb130-2" title="2"><span class="kw">mean</span>(x <span class="op">&lt;</span><span class="st"> </span>(mu <span class="op">-</span><span class="st"> </span>k <span class="op">*</span><span class="st"> </span>stdev) <span class="op">|</span><span class="st"> </span>x <span class="op">&gt;</span><span class="st"> </span>(mu <span class="op">+</span><span class="st"> </span>k <span class="op">*</span><span class="st"> </span>stdev))</a></code></pre></div>
<pre><code>## [1] 0.01</code></pre>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb132-1" title="1"><span class="co"># What proportion/probability of TRUEs would we expect under a normal probability distribution?</span></a>
<a class="sourceLine" id="cb132-2" title="2"><span class="kw">pnorm</span>(k) <span class="co"># probability of observing a value less than k standard deviations above the mean</span></a></code></pre></div>
<pre><code>## [1] 0.9772499</code></pre>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb134-1" title="1"><span class="kw">pnorm</span>(<span class="op">-</span>k) <span class="co"># probability of observing a value less than k standard deviations below the mean</span></a></code></pre></div>
<pre><code>## [1] 0.02275013</code></pre>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb136-1" title="1">(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">pnorm</span>(k) <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="op">-</span>k))) <span class="co"># probability of observing an extreme value</span></a></code></pre></div>
<pre><code>## [1] 0.04550026</code></pre>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb138-1" title="1"><span class="co"># So putting it all together, we have the ratio of:</span></a>
<a class="sourceLine" id="cb138-2" title="2"><span class="co"># the probability of observing an extreme value in the data, over the</span></a>
<a class="sourceLine" id="cb138-3" title="3"><span class="co"># the probability of observing an extreme value in a normal distribution:</span></a>
<a class="sourceLine" id="cb138-4" title="4"><span class="kw">mean</span>(x <span class="op">&lt;</span><span class="st"> </span>(mu <span class="op">-</span><span class="st"> </span>k <span class="op">*</span><span class="st"> </span>stdev) <span class="op">|</span><span class="st"> </span>x <span class="op">&gt;</span><span class="st"> </span>(mu <span class="op">+</span><span class="st"> </span>k <span class="op">*</span><span class="st"> </span>stdev))<span class="op">/</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">pnorm</span>(k) <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="op">-</span>k)))</a></code></pre></div>
<pre><code>## [1] 0.2197789</code></pre>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb140-1" title="1"><span class="kw">compare.tail.to.normal</span>(<span class="dt">x =</span> x, <span class="dt">k =</span> k, <span class="dt">mu =</span> mu, <span class="dt">sigma =</span> stdev)</a></code></pre></div>
<pre><code>## [1] 0.2197789</code></pre>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb142-1" title="1"><span class="co"># If this ratio is &lt; 1, then the data have fewer extreme values than suggested by a normal</span></a>
<a class="sourceLine" id="cb142-2" title="2"><span class="co"># If this ratio is &gt; 1, then the data have more extreme values than suggested by a normal</span></a></code></pre></div>
<p>Above, I haven’t computed the means of many simulations - which is the crux of the question! So here I just paste Edge’s solution. In it, he calculates <span class="math inline">\(E(X)\)</span> and <span class="math inline">\(Var(X)\)</span> using the Pareto probability distribution. I have changed <code>n</code> and <code>n.sim</code> to match my values above.</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb143-1" title="1"><span class="co">#Sample size per simulation (n) and number of simulations.</span></a>
<a class="sourceLine" id="cb143-2" title="2">n &lt;-<span class="st"> </span><span class="dv">100</span></a>
<a class="sourceLine" id="cb143-3" title="3">n.sim &lt;-<span class="st"> </span><span class="dv">10000</span></a>
<a class="sourceLine" id="cb143-4" title="4"><span class="co">#Pareto parameters. Variance is finite, and so</span></a>
<a class="sourceLine" id="cb143-5" title="5"><span class="co">#CLT applies, if a &gt; 2. For large a, convergence to</span></a>
<a class="sourceLine" id="cb143-6" title="6"><span class="co">#normal is better. With small a, convergence is slow,</span></a>
<a class="sourceLine" id="cb143-7" title="7"><span class="co">#especially in the tails.</span></a>
<a class="sourceLine" id="cb143-8" title="8">a &lt;-<span class="st"> </span><span class="dv">4</span></a>
<a class="sourceLine" id="cb143-9" title="9">b &lt;-<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb143-10" title="10"><span class="co">#Compute the expectation and variance of the distribution</span></a>
<a class="sourceLine" id="cb143-11" title="11"><span class="co">#of the sample mean. a must be above 2 for these expressions</span></a>
<a class="sourceLine" id="cb143-12" title="12"><span class="co">#to hold.</span></a>
<a class="sourceLine" id="cb143-13" title="13">expec.par &lt;-<span class="st"> </span>a<span class="op">*</span>b<span class="op">/</span>(a<span class="dv">-1</span>)</a>
<a class="sourceLine" id="cb143-14" title="14">var.par &lt;-<span class="st"> </span>a<span class="op">*</span>b<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>((a<span class="dv">-1</span>)<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(a<span class="dv">-2</span>))</a>
<a class="sourceLine" id="cb143-15" title="15">sd.mean &lt;-<span class="st"> </span><span class="kw">sqrt</span>(var.par <span class="op">/</span><span class="st"> </span>n)</a>
<a class="sourceLine" id="cb143-16" title="16"><span class="co">#Simulate data</span></a>
<a class="sourceLine" id="cb143-17" title="17">sim &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rpareto</span>(n<span class="op">*</span>n.sim, a, b), <span class="dt">nrow =</span> n.sim)</a>
<a class="sourceLine" id="cb143-18" title="18"><span class="co"># Each column represents ith sample taken per simulation</span></a>
<a class="sourceLine" id="cb143-19" title="19"><span class="co"># Each row represents a different simulation</span></a>
<a class="sourceLine" id="cb143-20" title="20">sim[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>]</a></code></pre></div>
<pre><code>##          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
## [1,] 1.146496 1.029705 1.334946 1.060409 1.013868 1.038984 1.804409 1.299151
## [2,] 1.342433 1.205436 1.003869 3.416952 2.248103 1.023516 1.006624 1.044363
## [3,] 1.076866 1.027499 1.061844 1.071026 1.425200 1.069973 1.456830 1.757125
##          [,9]    [,10]
## [1,] 1.153548 1.276303
## [2,] 1.074918 1.304583
## [3,] 1.042708 1.099849</code></pre>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb145-1" title="1"><span class="co"># Compute sample means.</span></a>
<a class="sourceLine" id="cb145-2" title="2">means.sim &lt;-<span class="st"> </span><span class="kw">rowMeans</span>(sim)</a>
<a class="sourceLine" id="cb145-3" title="3"><span class="kw">str</span>(means.sim)</a></code></pre></div>
<pre><code>##  num [1:10000] 1.38 1.34 1.33 1.28 1.34 ...</code></pre>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb147-1" title="1"><span class="co">#Draw a histogram of the sample means along with the approximate</span></a>
<a class="sourceLine" id="cb147-2" title="2"><span class="co">#normal pdf that follows from the CLT.</span></a>
<a class="sourceLine" id="cb147-3" title="3"><span class="kw">hist</span>(means.sim, <span class="dt">prob =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb147-4" title="4"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x, expec.par, sd.mean), <span class="dt">add =</span> <span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">&#39;red&#39;</span>)</a></code></pre></div>
<p><img src="05_random-variables_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb148-1" title="1"><span class="kw">compare.tail.to.normal</span>(means.sim, <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, expec.par, sd.mean)</a></code></pre></div>
<pre><code>## [1] 0.9639022</code></pre>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb150-1" title="1"><span class="kw">compare.tail.to.normal</span>(means.sim, <span class="dv">1</span>, expec.par, sd.mean)</a></code></pre></div>
<pre><code>## [1] 0.9407189</code></pre>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb152-1" title="1"><span class="kw">compare.tail.to.normal</span>(means.sim, <span class="dv">2</span>, expec.par, sd.mean)</a></code></pre></div>
<pre><code>## [1] 0.9384561</code></pre>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb154-1" title="1"><span class="kw">compare.tail.to.normal</span>(means.sim, <span class="dv">3</span>, expec.par, sd.mean)</a></code></pre></div>
<pre><code>## [1] 2.18535</code></pre>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb156-1" title="1"><span class="kw">compare.tail.to.normal</span>(means.sim, <span class="dv">4</span>, expec.par, sd.mean)</a></code></pre></div>
<pre><code>## [1] 25.25951</code></pre>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb158-1" title="1"><span class="kw">compare.tail.to.normal</span>(means.sim, <span class="dv">5</span>, expec.par, sd.mean)</a></code></pre></div>
<pre><code>## [1] 348.8556</code></pre>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb160-1" title="1"><span class="kw">compare.tail.to.normal</span>(means.sim, <span class="dv">6</span>, expec.par, sd.mean)</a></code></pre></div>
<pre><code>## [1] 0</code></pre>
</div>
</div>
<div id="a-probabilistic-model-for-simple-linear-regression" class="section level2">
<h2><span class="header-section-number">5.6</span> A probabilistic model for simple linear regression</h2>
<p>In this last section, we are going to apply the probabilistic concepts to our linear function:</p>
<p><span class="math display">\[
\begin{aligned}
Y = \alpha + \beta X + \epsilon \\
\end{aligned}
\]</span></p>
<p><span class="math inline">\(X, Y, \epsilon\)</span>: random variables (probability distributions)</p>
<p><span class="math inline">\(\alpha, \beta\)</span>: fixed coefficients (scalars)</p>
<p>In words, we are trying to model <span class="math inline">\(Y\)</span> as a linear function of <span class="math inline">\(\alpha, \beta, X\)</span>, plus a random disturbance, <span class="math inline">\(\epsilon\)</span>.</p>
<p>In what follows, we are going to make some simplifying assumptions about the random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(\epsilon\)</span>.</p>
<p>Why?</p>
<p>Because in doing so, we can make some <em>claims</em> about <span class="math inline">\(Y\)</span> - its expectation, and variance; as well as Cov(<span class="math inline">\(X, Y\)</span>).</p>
<p>Why is it useful to make these claims?</p>
<p>Because in doing so, we will be able to decompose the variance of <span class="math inline">\(Y\)</span> into two components: the effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, and the disturbance <span class="math inline">\(\epsilon\)</span>. That is, we’ll be able to generate predictions for <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span> - maybe we can predict <span class="math inline">\(Y\)</span> really well, or maybe not.</p>
<p>I will briefly restate the assumptions below.</p>
<div id="assumptions-of-the-linear-model" class="section level3">
<h3><span class="header-section-number">5.6.1</span> Assumptions of the linear model</h3>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X\)</span> has a known expectation, and the disturbance term has an expectation of 0:</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\text{E}(X) =&amp; ~ \mu_X \\
\text{E}(\epsilon) =&amp; ~ 0 \\
\end{aligned}
\]</span></p>
<p><em>Consequence: we know the expectation of <span class="math inline">\(Y\)</span></em></p>
<ol start="2" style="list-style-type: decimal">
<li>The expectation of the disturbance term is 0 for <em>all</em> values of <span class="math inline">\(X\)</span>:</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\text{E}(\epsilon | X = x) =&amp; ~ 0 \\
\end{aligned}
\]</span>
<em>Consequence: the conditional expectation of <span class="math inline">\(Y\)</span>, given any <span class="math inline">\(x\)</span>, can be predicted using a line with a slope <span class="math inline">\(\beta\)</span> and intercept <span class="math inline">\(\alpha\)</span>. Let that sink in…if this is not true, then the relationship between X and Y is not linear!</em></p>
<ol start="3" style="list-style-type: decimal">
<li>The variance of the disturbance is constant, for every <span class="math inline">\(x\)</span>:</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\text{Var}(\epsilon | X = x) =&amp; ~ \sigma^2_\epsilon \\
\end{aligned}
\]</span></p>
<p><em>Consequence: the variance of Y, for any x, is constant</em></p>
<ol start="4" style="list-style-type: decimal">
<li><span class="math inline">\(X\)</span> and <span class="math inline">\(\epsilon\)</span> are independent.</li>
</ol>
<p><em>Consequence: the variance of Y is due to the variation in X, plus the variation due to the disturbance</em></p>
</div>
<div id="important-claims-that-follow-from-these-assumptions" class="section level3">
<h3><span class="header-section-number">5.6.2</span> Important claims that follow from these assumptions</h3>
<p>The correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is:</p>
<p><span class="math display">\[
\begin{aligned}
\rho_{X, Y} = \beta \frac{\sigma_X}{\sigma_Y}\\
\end{aligned}
\]</span></p>
<p>The proportion of variance in <span class="math inline">\(Y\)</span> that is explained by <span class="math inline">\(X\)</span> (<span class="math inline">\(r^2\)</span>) is:</p>
<p><span class="math display">\[
\begin{aligned}
\rho_{X, Y}^2 = 1 - \frac{\text{Var}(Y|X = x)}{\text{Var}(Y)}\\
\end{aligned}
\]</span></p>
</div>
<div id="checking-these-assumptions" class="section level3">
<h3><span class="header-section-number">5.6.3</span> Checking these assumptions</h3>
<p>So you have run a linear model in R using <code>lm()</code>. Now what? Check your assumptions, of course! The most important assumptions are <em>linearity</em> (# 2 above) and <em>homoscedasticity</em> (#3 above). To check these, plot the residuals of your model against the fitted values.</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb162-1" title="1"><span class="kw">plot</span>(y1 <span class="op">~</span><span class="st"> </span>x1, <span class="dt">data =</span> anscombe)</a></code></pre></div>
<p><img src="05_random-variables_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb163-1" title="1">lm1 &lt;-<span class="st"> </span><span class="kw">lm</span>(y1 <span class="op">~</span><span class="st"> </span>x1, <span class="dt">data =</span> anscombe)</a>
<a class="sourceLine" id="cb163-2" title="2"><span class="kw">plot</span>(lm1, <span class="dt">which =</span> <span class="dv">1</span>)</a></code></pre></div>
<p><img src="05_random-variables_files/figure-html/unnamed-chunk-11-2.png" width="672" /></p>
<p>There should be no trend in the residuals (indicative of <em>linearity</em>), and the scatter of the residuals should be consistent across the range of fitted values (indicative of <em>homoscedasticity</em>). In the plot above, both of these assumptions are satisfied. Hopefully your residuals will look like this (if not, you have more work to do!).</p>
<p>Here is a figure (7.5) from Faraway (2002) that illustrates clear violations of these two assumptions:</p>
<p><img src="images/Faraway_fig7.5.png" style="width:150.0%" /></p>
</div>
<div id="exercise-set-5-5" class="section level3">
<h3><span class="header-section-number">5.6.4</span> Exercise set 5-5</h3>
<ol style="list-style-type: decimal">
<li>Write the square of the correlation coefficient (eq. 5.30) in terms of the variance of Y (eq. 5.32) and the conditional variance of Y given X (eq. 5.31).</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\text{eq. 5.30: } \rho_{X,Y} =&amp; \beta \frac{\sigma_X}{\sigma_Y} \\
\text{eq. 5.31: } Var(Y) =&amp; \beta^2 \sigma_X^2 + \sigma_{\epsilon}^2 \\
\text{eq. 5.32: } Var(Y \mid X = x) =&amp; \sigma_{\epsilon}^2  \\
\end{aligned}
\]</span></p>
<p>Squaring <span class="math inline">\(\rho_{X,Y}\)</span>, and expressing <span class="math inline">\(Var(Y)\)</span> using the definition from above:</p>
<p><span class="math display">\[
\begin{aligned}
\rho_{X,Y}^2 = \beta^2 \frac{\sigma_X^2}{\sigma_Y^2} = \beta^2 \frac{\sigma_X^2}{Var(Y)} \\
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\rho_{X,Y}^2 =  \beta^2 \frac{\sigma_X^2}{\beta^2 \sigma_X^2 + \sigma_{\epsilon}^2} \\
\end{aligned}
\]</span></p>
<p>Now, we have to employ an algebraic slight of hand. We rewrite the terms on the right as a single fraction, and by adding and subtracting the term <span class="math inline">\(\sigma_{\epsilon}^2\)</span> to the numerator, the numerator remains unchanged, but in a useful form to separate the single fraction into two, with the lefthand fraction equaling 1:</p>
<p><span class="math display">\[
\begin{aligned}
\rho_{X,Y}^2 =&amp; \frac{\beta^2 \sigma_X^2}{\beta^2 \sigma_X^2 + \sigma_{\epsilon}^2} \\
=&amp; \frac{(\beta^2 \sigma_X^2 + \sigma_{\epsilon}^2) - \sigma_{\epsilon}^2}{\beta^2 \sigma_X^2 + \sigma_{\epsilon}^2} \\
=&amp; \frac{\beta^2 \sigma_X^2 + \sigma_{\epsilon}^2}{\beta^2 \sigma_X^2 + \sigma_{\epsilon}^2} - \frac{\sigma_{\epsilon}^2}{\beta^2 \sigma_X^2 + \sigma_{\epsilon}^2} \\
=&amp; 1 - \frac{\sigma_{\epsilon}^2}{\beta^2 \sigma_X^2 + \sigma_{\epsilon}^2} \\
\end{aligned}
\]</span></p>
<p>And we use the formulas from above again to restate as:</p>
<p><span class="math display">\[
\begin{aligned}
\rho_{X,Y}^2 =&amp; 1 - \frac{Var(Y \mid X = x)}{Var(Y)} \\
\end{aligned}
\]</span></p>
<p>which gives us the ‘proportion of variance explained’. So if there isn’t much variance left in <span class="math inline">\(Y\)</span> after conditioning on <span class="math inline">\(X\)</span> (i.e., the numerator is small relative to the denominator), if we subtract it from 1, we get a high <span class="math inline">\(r^2\)</span>. And vice versa.</p>
<ol start="2" style="list-style-type: decimal">
<li>Simulating a regression.</li>
</ol>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb164-1" title="1"><span class="kw">library</span>(stfspack)</a>
<a class="sourceLine" id="cb164-2" title="2">sim.lm</a></code></pre></div>
<pre><code>## function (n, a, b, sigma.disturb = 1, mu.x = 8, sigma.x = 2, 
##     rdisturb = rnorm, rx = rnorm, het.coef = 0) 
## {
##     x &lt;- sort(rx(n, mu.x, sigma.x))
##     disturbs &lt;- rdisturb(n, 0, sapply(sigma.disturb + scale(x) * 
##         het.coef, max, 0))
##     y &lt;- a + b * x + disturbs
##     cbind(x, y)
## }
## &lt;bytecode: 0x7f9be1e4f8e0&gt;
## &lt;environment: namespace:stfspack&gt;</code></pre>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb166-1" title="1">sim_<span class="dv">0</span>_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">sim.lm</span>(<span class="dt">n =</span> <span class="dv">50</span>, <span class="dt">a =</span> <span class="dv">0</span>, <span class="dt">b =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb166-2" title="2"><span class="kw">head</span>(sim_<span class="dv">0</span>_<span class="dv">1</span>)</a></code></pre></div>
<pre><code>##             x        y
## [1,] 3.427344 2.949380
## [2,] 3.616894 3.644965
## [3,] 3.815677 4.193751
## [4,] 3.912910 3.364430
## [5,] 4.458928 6.025582
## [6,] 5.078764 3.985045</code></pre>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb168-1" title="1"><span class="kw">plot</span>(sim_<span class="dv">0</span>_<span class="dv">1</span>[,<span class="dv">1</span>], sim_<span class="dv">0</span>_<span class="dv">1</span>[,<span class="dv">2</span>])</a></code></pre></div>
<p><img src="05_random-variables_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Still using all the default values for parameters, but I have made all the arguments explicit in the function call:</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb169-1" title="1">sim_<span class="dv">0</span>_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">sim.lm</span>(<span class="dt">n =</span> <span class="dv">50</span>, <span class="dt">a =</span> <span class="dv">0</span>, <span class="dt">b =</span> <span class="dv">1</span>,</a>
<a class="sourceLine" id="cb169-2" title="2">                  <span class="dt">sigma.disturb =</span> <span class="dv">1</span>, <span class="dt">mu.x =</span> <span class="dv">8</span>, <span class="dt">sigma.x =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb169-3" title="3">                  <span class="dt">rdisturb =</span> rnorm, <span class="dt">rx =</span> rnorm, <span class="dt">het.coef =</span> <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb169-4" title="4"><span class="kw">plot</span>(sim_<span class="dv">0</span>_<span class="dv">1</span>[,<span class="dv">1</span>], sim_<span class="dv">0</span>_<span class="dv">1</span>[,<span class="dv">2</span>])</a></code></pre></div>
<p><img src="05_random-variables_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Now I’ll change one at a time. Here, I’ve doubled <code>sigma.disturb</code>, the error term:</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb170-1" title="1">sim_<span class="dv">0</span>_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">sim.lm</span>(<span class="dt">n =</span> <span class="dv">50</span>, <span class="dt">a =</span> <span class="dv">0</span>, <span class="dt">b =</span> <span class="dv">1</span>,</a>
<a class="sourceLine" id="cb170-2" title="2">                  <span class="dt">sigma.disturb =</span> <span class="dv">2</span>, <span class="dt">mu.x =</span> <span class="dv">8</span>, <span class="dt">sigma.x =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb170-3" title="3">                  <span class="dt">rdisturb =</span> rnorm, <span class="dt">rx =</span> rnorm, <span class="dt">het.coef =</span> <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb170-4" title="4"><span class="kw">plot</span>(sim_<span class="dv">0</span>_<span class="dv">1</span>[,<span class="dv">1</span>], sim_<span class="dv">0</span>_<span class="dv">1</span>[,<span class="dv">2</span>])</a></code></pre></div>
<p><img src="05_random-variables_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Next, I have doubled E(<span class="math inline">\(X\)</span>):</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb171-1" title="1">sim_<span class="dv">0</span>_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">sim.lm</span>(<span class="dt">n =</span> <span class="dv">50</span>, <span class="dt">a =</span> <span class="dv">0</span>, <span class="dt">b =</span> <span class="dv">1</span>,</a>
<a class="sourceLine" id="cb171-2" title="2">                  <span class="dt">sigma.disturb =</span> <span class="dv">1</span>, <span class="dt">mu.x =</span> <span class="dv">16</span>, <span class="dt">sigma.x =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb171-3" title="3">                  <span class="dt">rdisturb =</span> rnorm, <span class="dt">rx =</span> rnorm, <span class="dt">het.coef =</span> <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb171-4" title="4"><span class="kw">plot</span>(sim_<span class="dv">0</span>_<span class="dv">1</span>[,<span class="dv">1</span>], sim_<span class="dv">0</span>_<span class="dv">1</span>[,<span class="dv">2</span>])</a></code></pre></div>
<p><img src="05_random-variables_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Next, I have doubled <span class="math inline">\(\sigma_X\)</span>:</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb172-1" title="1">sim_<span class="dv">0</span>_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">sim.lm</span>(<span class="dt">n =</span> <span class="dv">50</span>, <span class="dt">a =</span> <span class="dv">0</span>, <span class="dt">b =</span> <span class="dv">1</span>,</a>
<a class="sourceLine" id="cb172-2" title="2">                  <span class="dt">sigma.disturb =</span> <span class="dv">1</span>, <span class="dt">mu.x =</span> <span class="dv">8</span>, <span class="dt">sigma.x =</span> <span class="dv">4</span>,</a>
<a class="sourceLine" id="cb172-3" title="3">                  <span class="dt">rdisturb =</span> rnorm, <span class="dt">rx =</span> rnorm, <span class="dt">het.coef =</span> <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb172-4" title="4"><span class="kw">plot</span>(sim_<span class="dv">0</span>_<span class="dv">1</span>[,<span class="dv">1</span>], sim_<span class="dv">0</span>_<span class="dv">1</span>[,<span class="dv">2</span>])</a></code></pre></div>
<p><img src="05_random-variables_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>Finally, here I have changed the distribution of the error term to a laplace distribution:</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb173-1" title="1">sim_<span class="dv">0</span>_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">sim.lm</span>(<span class="dt">n =</span> <span class="dv">50</span>, <span class="dt">a =</span> <span class="dv">0</span>, <span class="dt">b =</span> <span class="dv">1</span>,</a>
<a class="sourceLine" id="cb173-2" title="2">                  <span class="dt">sigma.disturb =</span> <span class="dv">1</span>, <span class="dt">mu.x =</span> <span class="dv">8</span>, <span class="dt">sigma.x =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb173-3" title="3">                  <span class="dt">rdisturb =</span> rlaplace, <span class="dt">rx =</span> rnorm, <span class="dt">het.coef =</span> <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb173-4" title="4"><span class="kw">plot</span>(sim_<span class="dv">0</span>_<span class="dv">1</span>[,<span class="dv">1</span>], sim_<span class="dv">0</span>_<span class="dv">1</span>[,<span class="dv">2</span>])</a></code></pre></div>
<p><img src="05_random-variables_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probability.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="estimators.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
